{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5376112b",
   "metadata": {},
   "source": [
    "# PyGRAPES Simulation script\n",
    "\n",
    "## with default settings, this requires a GPU and uses approximately 5GB of VRAM. \n",
    "#### The simulation reconstructs a Au Siemens Star with height of 5 nm from simulated data.\n",
    "#### running the notebook on CPU is in principle possible, but has not been tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb814f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.io\n",
    "import h5py\n",
    "import matplotlib.patches as patches\n",
    "import sys\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import gc\n",
    "import torchvision\n",
    "from datetime import datetime\n",
    "from skimage.draw import disk, ellipse\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from IPython.display import display, clear_output\n",
    "from torchvision.transforms import v2\n",
    "import os\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173e2581-9ce0-46e5-a8c1-83e4376e755f",
   "metadata": {},
   "source": [
    "## Check CUDA is available.\n",
    "\n",
    "### in principle, the code should be able to run without a CUDA device, but this has not been tested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd315a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!nvidia-smi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac3cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cuda device count:\",torch.cuda.device_count())\n",
    "print(\"cuda available:\",torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device('cuda:0')\n",
    "    torch.cuda.set_device('cuda:0')\n",
    "    print(\"setting default device to cuda\")\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "\n",
    "    for i in range(num_gpus):\n",
    "        # Get device properties\n",
    "        # device = torch.device(f'cuda:{i}')\n",
    "        properties = torch.cuda.get_device_properties(torch.device(f'cuda:{i}'))\n",
    "\n",
    "        # Print the total memory on the current GPU\n",
    "        print(f\"GPU {i}: {properties.name}, Total Memory: {properties.total_memory / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(\"current CUDA device is\", current_device)\n",
    "else: \n",
    "    print(\"cuda is not available. default device is CPU. Not tested\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d987ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_memcheck():\n",
    "    allocated_memory = torch.cuda.memory_allocated()\n",
    "    print(\"Currently allocated memory:\", allocated_memory // (1024 * 1024), \"MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d720d4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ed43681-feef-479a-8abe-57584e13e664",
   "metadata": {},
   "source": [
    "# Input Settings \n",
    "\n",
    "### The following 3 cells are where reconstruction settings are defined, such as simulation size, resolution, wavelength, and many others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41236ca0-e99f-41f8-a276-09e10ce03cae",
   "metadata": {},
   "source": [
    "## (1/3)  Define Initial volume size and detector window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd5aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size = torch.tensor((5e-9,40e-9)) # (x,y) (normal to surface, perpendicular to x-ray propagation direction)\n",
    "slab_thickness = torch.tensor(500e-9) #z-direction resolution, parallel to x-ray propagation direction (thickness of 1 slice in multislice)\n",
    "full_sim_size = [1300,250,750] #a tuple specifying x,y,z size of the full volume.\n",
    "params_size = [10,full_sim_size[1],full_sim_size[2]] # a tuple specifying x,y,z size of optimizable structure (default y, and z are the same as full_sim_size).\n",
    "crop_window_size = [400,180] #[vertical pixels, horizontal pixels] equivalent to the window size of the detector used in in conventional ptychography (\"asize\" in ptychoshelves, for example).\n",
    "print(\"Voxel size, x:\", (voxel_size[0]*1e9).item(), \"nm, y:\",(voxel_size[1]*1e9).item(), \"nm\")\n",
    "print(\"Slab thickness:\", (slab_thickness*1e9).item(),\"nm\")\n",
    "\n",
    "\n",
    "probe_buffer = 0 #not used, but leave as 0\n",
    "shift_amount = 0 #not used, but leave as 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540fed2e-446a-461b-af6d-68b3fa337ea7",
   "metadata": {},
   "source": [
    "## (2/3) Define Experimental Wavelength, and define any refractive indices to be used in the reconstruction.\n",
    "\n",
    "##### the code refers to Audelta and Aubeta but these can be changed for other materials if the variable name is kept the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21bdd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_val = torch.tensor(1.99983862803066e-10) #simulation Wavelength. Default  = 6.02 keV (commonly used at cSAXS, PSI)\n",
    "Audelta = torch.tensor(7.99106419e-05) #Since this simulation is only Au, we are just defining Au delta and beta for this energy.\n",
    "Aubeta = torch.tensor(1.24435501e-05) #Since this simulation is only Au, we are just defining Au delta and beta for this energy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f0b967-5891-4f8f-8c4a-f597210dffa8",
   "metadata": {},
   "source": [
    "## (3/3) Define Reconstruction specific Parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb472cd4-944a-4b38-b39a-51b78577f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization settings.\n",
    "using_n_scans_per_pixel = True #leave as true\n",
    "do_gradient_accumulation = True #whether structure is optimized after each scan (false), or after all scans are calculated (True) . Best left as true.\n",
    "load_previous = False #if loading a previously saved/optimised \n",
    "use_per_scan_TV = False #True means TV is calculated just for scan region rather than entire volume. best to leave as false.\n",
    "use_multiple_probe_modes = True #true probe mode modelling is not  implemented, but leave as true regardless.\n",
    "use_noise = True #best left as true, if noise is not needed, you can set noise to zero and noise LR to zero. False disables noise modelling entirely.\n",
    "optimize_scan_offsets = True #whether subpixel shifts and scan positions are optimized. Can leave as true, and set LR to zero.\n",
    "oversample_structure = True #whether to apply oversampling, more z slices than are used in the simulation. Leave as true, and set to 1, to not use oversampling.\n",
    "oversample_factor = 1 #leave as 1 to effectively turn oversampling off.\n",
    "\n",
    "# set learning rates and initial guesses.\n",
    "init_xr_scaling_factor = 0.02 #the magnitude (in voxels) of random fluctuatoin of your initial guess.\n",
    "init_xr_substrateamt = 0.00 #provide an offset of all initial values of initial guess.\n",
    "init_xr_learning_rate = 1e5 #initial learning rate seems high, but 1e5 has been tested to work reasonably well. \n",
    "grads_target = 0.1 #not used, leave at 0.1\n",
    "scan_positions_LR_fine = 1e-15 #per scan position optimization\n",
    "scan_positions_LR_coarse = 5e-15#position optimization of an entire set of scans. useful for coarse motor translations in stitch scans.\n",
    "probe_prop_LR = 1e-4 #not used at the moment.\n",
    "noise_std = 0 #noise init guess follows a gaussian dist, this provides Standard dev.\n",
    "noise_mean = 0 #noise init guess follows a gaussian dist, this provides mean.\n",
    "probe_grads_target = 1.0e-8 #rather than a learning rate, the probe has an average value of gradients, so that optimization is on average around the magnitude of this parameter\n",
    "\n",
    "#total variation regularization\n",
    "tvx_strength = 1 #to change the relative intensity of total variation in X direction. Not used in demo script.\n",
    "tvy_strength = 1 #to change the relative intensity of total variation in Y direction. Best left at 1 initially.\n",
    "tvz_strength = 1 #to change the relative intensity of total variation in Z direction. Best left at 1 initially.\n",
    "total_TV_strength = 1e-3 #total contributoin of ALL total variation penalty.\n",
    "\n",
    "#additional simulation settings.\n",
    "substrate_layers = 200 #number of layers from the bottom upwards of substrate. This shuold be enough to fully reflect/absorb the incoming beam.\n",
    "probe_substrate_buffer = 2 #extra spacing between probe and substrate.\n",
    "top_buffer = 0 #add padding in the final multislice component if the beam reflects too early or too steeply.\n",
    "pre_prop_dist_multiplier = 1.5 #add extra propagation distance before the beam encounters the structure.\n",
    "post_prop_dist_multiplier = 1 #add extra propagation distance after the beam encounters the structure.\n",
    "test_inc_angle = 0.7 # the incidence angle to test out these settings.\n",
    "slab_pad_pre = 0 #add extra slices, not used, but necessary atm for code to run.\n",
    "slab_pad_post = 0 #add extra slices, not used , but necessary atm for code to run.\n",
    "\n",
    "# hyperparamters\n",
    "num_iters = 50 #number of iteratoins to run for.\n",
    "probestart = 2 #iteration number at which the probe will begin optimising.\n",
    "tv_start = 2 #iteration number at which TV penalty will begin to apply.\n",
    "patience = 5 #number of iterations to wait for reducing LR if loss function is increasing.\n",
    "divergence_count_start = 5 #when LR scheduling begins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1d58cc-d2cd-428a-b2e8-8a215e8193dc",
   "metadata": {},
   "source": [
    "# Define Auxiliary Functions\n",
    "\n",
    "### run this all and skip forward in the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2569bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wave_interact_partial_voxels(wave, c, slab_thickness, wavelength,ndelta,nbeta):\n",
    "    return wave * (c*torch.exp(1j * 2 * torch.pi * (ndelta+1j*nbeta) * slab_thickness / wavelength) + (1-c)*torch.exp(1j * 2 * torch.pi * (0+1j*0) * slab_thickness / wavelength))\n",
    "\n",
    "def wave_interact_partial_voxels_AuAg(wave, c, slab_thickness, wavelength,ndelta,nbeta):\n",
    "    wavetop,wavesub = torch.split(wave,[full_sim_size[0]-substrate_layers,substrate_layers])\n",
    "    ctop,csub = torch.split(c,[full_sim_size[0]-substrate_layers,substrate_layers])\n",
    "    top = wavetop* (ctop*torch.exp(1j * 2 * torch.pi * (ndelta+1j*nbeta) * slab_thickness / wavelength) + (1-ctop)*torch.exp(1j * 2 * torch.pi * (0+1j*0) * slab_thickness / wavelength))\n",
    "    substrate = wavesub * (csub*torch.exp(1j * 2 * torch.pi * (Audelta+1j*Aubeta) * slab_thickness / wavelength))\n",
    "    return torch.cat((top,substrate),dim=0)\n",
    "\n",
    "def wave_interact_full_complex(wave, c, slab_thickness, wavelength):\n",
    "    return wave * torch.exp(1j * 2 * torch.pi * (c) * slab_thickness / wavelength) \n",
    "\n",
    "def wave_interact_AndProp_partial_voxels_deltabeta(wave, c_r, c_i, slab_thickness, wavelength,ndelta,nbeta,tf):\n",
    "    wave = torch.fft.ifft2(torch.fft.fft2(wave*torch.exp(1j * 2 * torch.pi * \n",
    "            (ndelta*(c_r)+1j*nbeta*c_i) * slab_thickness / wavelength))*torch.exp(tf)) \n",
    "    return wave\n",
    "\n",
    "def optimise_probe_prop(probe_in,propdist,lambda_val,voxel_size):\n",
    "    h1 = get_tf_longprop(propdist,lambda_val,voxel_size,probe_in.size())\n",
    "    propped_probe_optimised = longprop(probe_in,h1)\n",
    "\n",
    "    return propped_probe_optimised\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da3f7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c646d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_freq_mesh(voxel_size,shape):\n",
    "    u = torch.fft.fftfreq(shape[1])\n",
    "    v = torch.fft.fftfreq(shape[0])\n",
    "    vv,uu = torch.meshgrid(v,u)\n",
    "    vv = vv/voxel_size[0]\n",
    "    uu = uu/voxel_size[1]\n",
    "    return uu,vv\n",
    "# uutest,_ = create_freq_mesh(voxel_size,full_sim_size)\n",
    "# plt.imshow(uutest.cpu())\n",
    "def get_tf_longprop(propdist,lambda_val,voxel_size,grid_shape):\n",
    "    u,v = create_freq_mesh(voxel_size,grid_shape)\n",
    "    H = torch.exp(-1 * 1j*torch.pi*lambda_val*propdist*(u**2+v**2))\n",
    "    return H\n",
    "\n",
    "def get_tf_nearfield(propdist,lambda_val,voxel_size,grid_shape):\n",
    "    u,v = create_freq_mesh(voxel_size,grid_shape)\n",
    "    quad = 1-(u**2+v**2)*(lambda_val**2)\n",
    "    quad_inner = torch.clamp(quad,min=0)\n",
    "    quad_mask = quad>0\n",
    "    H = (2j * torch.pi * (propdist / lambda_val)*torch.sqrt(quad_inner))\n",
    "    \n",
    "    return H * quad_mask\n",
    "\n",
    "def farfield_PSI_prop(wave_in,lambda_val,propdist,voxel_size):\n",
    "    N = wave_in.size()\n",
    "    g1 = torch.arange(-(N[0]/2),(np.floor((N[0]-1)/2)))\n",
    "    g2 = torch.arange(-(N[1]/2),(np.floor((N[1]-1)/2)))\n",
    "    [x,y] = torch.meshgrid(g1,g2)\n",
    "    r2 = x**2+y**2\n",
    "    propdist = propdist/voxel_size[0]\n",
    "    lambda_val = lambda_val/voxel_size[0]\n",
    "    wout = -1j * torch.exp(1j * torch.pi * lambda_val * propdist * r2 / (N[0]*N[1])) * torch.fft.ifftshift(torch.fft.fft2(torch.fft.fftshift(wave_in * torch.exp(1j * torch.pi * r2 / (lambda_val*propdist)))))\n",
    "    return wout\n",
    "\n",
    "def farfield_PSI_prop_2(wave_in,lambda_val,propdist,voxel_size):\n",
    "    N = wave_in.size()\n",
    "    g1 = torch.arange(-(N[0]/2),(np.floor((N[0]-1)/2)))\n",
    "    g2 = torch.arange(-(N[1]/2),(np.floor((N[1]-1)/2)))\n",
    "    [x,y] = torch.meshgrid(g1,g2)\n",
    "    r2 = x**2+y**2\n",
    "    u,v = create_freq_mesh(voxel_size,N)\n",
    "    u = torch.fft.fftshift(u)/(2*torch.max(u))\n",
    "    v = torch.fft.fftshift(v)/(2*torch.max(v))\n",
    "#     propdist = propdist/voxel_size[0]\n",
    "#     lambda_val = lambda_val/voxel_size[0]\n",
    "\n",
    "    H = torch.exp(1j * torch.pi * lambda_val/voxel_size[0] * propdist/voxel_size[0] * r2/(N[0]*N[1]))\n",
    "    pre_exp = -1j * H#torch.exp(1j * torch.pi * lambda_val * propdist * r2 / (N[0]*N[1]))\n",
    "    tf_inner = torch.exp(1j * torch.pi * r2 / ((lambda_val/voxel_size[0])*(propdist/voxel_size[0])))\n",
    "    tf_inner_x = torch.exp(1j * torch.pi * (x**2) / ((lambda_val/voxel_size[1])*(propdist/voxel_size[1])))\n",
    "    tf_inner_y = torch.fft.fftshift(torch.exp(1j * torch.pi * (y**2) / ((lambda_val/voxel_size[0])*(propdist/voxel_size[0]))))\n",
    "    wout = pre_exp * torch.fft.ifftshift(torch.fft.fft(torch.fft.fft(torch.fft.fftshift(wave_in*tf_inner_x),dim=0)*tf_inner_y,dim=1))\n",
    "    return wout\n",
    "\n",
    "def farfield_PSI_prop1d(wave_in,lambda_val,propdist,voxel_size):\n",
    "    N = wave_in.size()\n",
    "    g1 = torch.arange(-(N[0]/2),(np.floor((N[0]-1)/2)))\n",
    "    g2 = torch.arange(-(N[1]/2),(np.floor((N[1]-1)/2)))\n",
    "    [x,y] = torch.meshgrid(g1,g2)\n",
    "    r2 = x**2#+y**2\n",
    "    propdist = propdist/voxel_size\n",
    "    lambda_val = lambda_val/voxel_size\n",
    "    wout = -1j * torch.exp(1j * torch.pi * lambda_val * propdist * r2 / (N[0]**2)) * torch.fft.ifftshift(torch.fft.fft2(torch.fft.fftshift(wave_in * torch.exp(1j * torch.pi * r2 / (lambda_val*propdist)))))\n",
    "    return wout\n",
    "\n",
    "\n",
    "def longprop(wave_in,h):\n",
    "\n",
    "    f1 = torch.fft.fft2(wave_in)\n",
    "    oldflux = torch.sum(torch.abs(f1))\n",
    "    fh = (f1*h)\n",
    "    newflux = torch.sum(torch.abs(fh))\n",
    "    fluxratio = oldflux/newflux\n",
    "\n",
    "    return torch.fft.ifft2(fh)\n",
    "\n",
    "def wave_propagate_2d_RI(wavein,h):\n",
    "    f1 = torch.fft.fft2(wavein)\n",
    "    oldflux = torch.sum(torch.abs(f1))\n",
    "    h_exp = (torch.exp(h))\n",
    "#     h_real = torch.real(h_exp)\n",
    "#     h_imag = torch.imag(h_exp)\n",
    "    f1_real = torch.real(f1)\n",
    "    f1_imag = torch.imag(f1)\n",
    "    fh_real = f1_real * h_exp - f1_imag * h_exp\n",
    "    fh_imag = f1_real * h_exp + f1_imag * h_exp\n",
    "    fh = (fh_real)+1j*(fh_imag)\n",
    "    newflux = torch.sum(torch.abs(fh))\n",
    "    fluxratio = oldflux/newflux\n",
    "    return torch.fft.ifft2((fh*fluxratio))\n",
    "\n",
    "def fresnel_exit(wave_in,lambda_val,distance,dx,dy):\n",
    "    \n",
    "    k = 2*torch.pi/lambda_val\n",
    "    nx,ny = wave_in.shape\n",
    "    x = torch.linspace(-nx//2, nx//2 - 1, nx) * dx\n",
    "    y = torch.linspace(-ny//2, ny//2 - 1, ny) * dy\n",
    "    X, Y = torch.meshgrid(x, y, indexing='ij')\n",
    "    fx = torch.fft.fftfreq(nx, d=dx)\n",
    "    fy = torch.fft.fftfreq(ny, d=dy)\n",
    "    FX, FY = torch.meshgrid(fx, fy, indexing='ij')\n",
    "    input_wave_fft = torch.fft.fft2(wave_in)\n",
    "\n",
    "      # Compute the Fresnel propagation phase term in spatial domain\n",
    "    phase_term = torch.exp(1j * k * distance) * torch.exp(-1j * k / (2 * distance) * (X**2 + Y**2))\n",
    "    # Apply the phase term in the Fourier domain\n",
    "    output_wave_fft = input_wave_fft * phase_term\n",
    "    output_wave = (output_wave_fft)\n",
    "\n",
    "    \n",
    "    return output_wave,phase_term\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca7b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSForward_GI_SS_novol_partialvoxel_pre(xr,full_sim_size,params_size,voxel_size,slab_thickness,inc_angle,slab_pad_pre,slab_pad_post,probe,probe_buffer,wavemask,shift_amt,substrate_layers,init_xr_substrateamt,top_buffer,subpixel_shift_y,subpixel_shift_z,hx_shift,hz_shift):\n",
    "        \n",
    "        old_max = torch.max(torch.abs(torch.fft.fft2(probe)))\n",
    "        substrate_layers_pre = substrate_layers\n",
    "        substrate_start = (full_sim_size[0]-substrate_layers_pre)*voxel_size[0]\n",
    "#         probe_substrate_buffer = 20\n",
    "        probe_in = probe\n",
    "        probe_halfsize = (probe_in.size(0)*voxel_size[0])/2\n",
    "        probe_insertion_Y = int((full_sim_size[1] - probe_in.size(1))/2)\n",
    "        reflection_distance = 2*(probe_halfsize+probe_substrate_buffer*voxel_size[0])/(torch.tan(torch.deg2rad(torch.tensor(inc_angle))))\n",
    "        pre_post_amt = (reflection_distance - (xr.size(2)*slab_thickness)) / 2\n",
    "        new_c_wave_size = probe_in.size(0)+substrate_layers_pre+probe_substrate_buffer\n",
    "        if new_c_wave_size < full_sim_size[0]:\n",
    "            new_c_wave_size = full_sim_size[0]\n",
    "        c_wave = torch.complex(torch.zeros((new_c_wave_size),full_sim_size[1]),torch.zeros((new_c_wave_size),full_sim_size[1])).to(torch.complex64)\n",
    "\n",
    "        if pre_post_amt<0:\n",
    "            pre_post_amt = 1e-6\n",
    "        \n",
    "        n_slices = 50\n",
    "        pre_prop_dist = pre_post_amt/n_slices\n",
    "        newphantom = torch.zeros(c_wave.size(0),c_wave.size(1))\n",
    "        newphantom[-int(substrate_layers_pre):,:] = 1\n",
    "#         print(pre_prop_dist)\n",
    "#         print(new_c_wave_size)\n",
    "#         tf2 = (get_tf_nearfield(pre_prop_dist,lambda_val,voxel_size,c_wave.size()))\n",
    "        tf2 = get_tf_longprop(pre_prop_dist,lambda_val,voxel_size,c_wave.size())\n",
    "        probe_insertion_x_coords = ((substrate_layers+probe_substrate_buffer+probe_in.size(0)),(substrate_layers+probe_substrate_buffer))\n",
    "        if probe_insertion_x_coords[1] < substrate_layers:\n",
    "            probe_cutoff_amount = substrate_layers - probe_insertion_x_coords[1]\n",
    "            probe_in[-probe_cutoff_amount:,:] = 0\n",
    "        c_wave[-probe_insertion_x_coords[0]:-probe_insertion_x_coords[1],probe_insertion_Y:int(probe_insertion_Y+probe.size(1))] = probe_tilt_gradient(probe_in,inc_angle,voxel_size,pre_prop_dist)\n",
    "        c_wave = probe_subpixel_shift_fourier(c_wave,subpixel_shift_z,subpixel_shift_y,slab_thickness,voxel_size,hx_shift,hz_shift)\n",
    "        \n",
    "        for n1 in range(n_slices):\n",
    "            c_wave = wave_interact_partial_voxels(c_wave,newphantom,pre_prop_dist,lambda_val,Audelta,Aubeta)\n",
    "            c_wave = longprop(c_wave,tf2)#wave_propagate_2d_faster_usefilter(c_wave,tf2,1)#\n",
    "        \n",
    "        c_wave = torch.fft.ifft2(torch.fft.fft2(c_wave))\n",
    "        c_wave = c_wave[-int(full_sim_size[0]):,:]\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "        return c_wave,pre_post_amt,probe_insertion_Y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de055b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSForward_GI_SS_novol_partialvoxel_mid(xr,cwavein,full_sim_size,params_size,voxel_size,slab_thickness,inc_angle,substrate_layers):\n",
    "        c_wave = cwavein\n",
    "        \n",
    "#         tf = get_tf_nearfield(slab_thickness,lambda_val,voxel_size,c_wave.size())\n",
    "        tf = get_tf_longprop(slab_thickness,lambda_val,voxel_size,c_wave.size())\n",
    "        upscale_slices = int(torch.round(torch.tensor(full_sim_size[2]/xr.size(2))))\n",
    "        upscale_slices_x = int(torch.round(torch.tensor(params_size[0]/xr.size(0))))\n",
    "        us_size = (params_size[0],params_size[1])\n",
    "        midslice = torch.zeros(c_wave.size(1),xr.size(2))\n",
    "        sideslice = torch.zeros(c_wave.size(0),xr.size(2))\n",
    "        for n1 in range(xr.size(2)):\n",
    "            S1 = xr[:,:,n1]\n",
    "\n",
    "            this_slab = torch.nn.functional.pad(torch.nn.functional.pad(S1,(0,0,int(full_sim_size[0]-S1.size(0)-substrate_layers),0),value=0),(0,0,0,substrate_layers),value=1)\n",
    "\n",
    "            for n2 in range(upscale_slices):\n",
    "                if (torch.cuda.memory_allocated() / (1024**2)) > 24000:\n",
    "\n",
    "                    with torch.autograd.graph.save_on_cpu(pin_memory=True):\n",
    "                        c_wave = wave_interact_partial_voxels(c_wave,this_slab,slab_thickness,lambda_val,Audelta,Aubeta)\n",
    "                        c_wave = longprop(c_wave,tf)#wave_propagate_2d_faster_usefilter(c_wave,tf,1)\n",
    "#                         c_wave=c_wave*wavemask\n",
    "                else:\n",
    "                    c_wave = wave_interact_partial_voxels(c_wave, this_slab, slab_thickness, lambda_val,Audelta,Aubeta)\n",
    "\n",
    "                    c_wave = longprop(c_wave,tf)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    midslice[:,n1] = torch.abs(c_wave[-substrate_layers,:])\n",
    "                    sideslice[:,n1] = torch.abs(c_wave[:,int(full_sim_size[1]/2)])\n",
    "\n",
    "        return c_wave, midslice,sideslice\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af4e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSForward_GI_SS_novol_partialvoxel_post(xr,cwavein,full_sim_size,params_size,voxel_size,slab_thickness,inc_angle,substrate_layers,prepostdist,probe_insertion_Y,probesize,init_xr_substrateamt):\n",
    "        n_slices = 100\n",
    "        side_buffer = 50\n",
    "        pre_prop_dist = (prepostdist*post_prop_dist_multiplier)/n_slices\n",
    "        top_x_post = 200    \n",
    "        top_buffer = top_x_post\n",
    "        substrate_layers_pre = substrate_layers\n",
    "        c_wave = torch.nn.functional.pad(cwavein,(side_buffer,side_buffer,top_buffer,0),value=0)\n",
    "        \n",
    "        \n",
    "        newphantom = torch.zeros(c_wave.size(0),c_wave.size(1))\n",
    "        newphantom[-int(substrate_layers_pre):,:] = 1\n",
    "        tf2 = get_tf_longprop(pre_prop_dist,lambda_val,voxel_size,c_wave.size())\n",
    "        for n1 in range(n_slices):\n",
    "            c_wave = wave_interact_partial_voxels(c_wave,newphantom,pre_prop_dist,lambda_val,Audelta,Aubeta)\n",
    "            c_wave = longprop(c_wave,tf2)\n",
    "        c_wave = probe_tilt_gradient(c_wave,inc_angle,voxel_size,pre_prop_dist)\n",
    "\n",
    "        return c_wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff8312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multislice_3stage(this_xr,\n",
    "                full_sim_size, params_size, voxel_size, slab_thickness,\n",
    "                inc_angle, slab_pad_pre, slab_pad_post, probes_in_shifted,\n",
    "                probe_buffer,wave_deletion_mask,shift_amount,substrate_layers,init_xr_substrateamt,top_buffer,blankew,subpixel_shift_y,subpixel_shift_z,hx_shift,hz_shift):\n",
    "    probesize = probes_in_shifted.size()\n",
    "    \n",
    "\n",
    "    pre_EW,pre_post_amt,probe_insertion_Y = MSForward_GI_SS_novol_partialvoxel_pre(\n",
    "                        this_xr,\n",
    "                        full_sim_size, params_size, voxel_size, slab_thickness,\n",
    "                        inc_angle, slab_pad_pre, slab_pad_post, probes_in_shifted,\n",
    "                        probe_buffer,1,0,substrate_layers,init_xr_substrateamt,0,subpixel_shift_y,subpixel_shift_z,hx_shift,hz_shift)\n",
    "    midEW,midslice,sideslice = MSForward_GI_SS_novol_partialvoxel_mid(this_xr,pre_EW,\n",
    "                   full_sim_size,params_size,voxel_size,slab_thickness,inc_angle,(substrate_layers))\n",
    "\n",
    "    exit_wave = MSForward_GI_SS_novol_partialvoxel_post(this_xr,midEW,\n",
    "                    full_sim_size,params_size,voxel_size,slab_thickness,inc_angle,(substrate_layers),pre_post_amt,probe_insertion_Y,probesize,init_xr_substrateamt)\n",
    "\n",
    "    F1 = torch.abs(torch.fft.fftshift(torch.fft.fft2(exit_wave.flip(0))))\n",
    "    F1 = torch.nn.functional.interpolate(F1.unsqueeze(0).unsqueeze(0),size=(probesize),mode='bilinear').squeeze()\n",
    "\n",
    "    return F1,midslice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f598ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "def probe_tilt_gradient(probe,inc_angle,voxel_size,slab_thickness):\n",
    "        \n",
    "        phase_gradient_Y = torch.linspace(0,voxel_size[0]*probe.shape[0]*torch.tan(torch.deg2rad(torch.tensor(inc_angle))),probe.shape[0])\n",
    "        phase_gradient_X = torch.linspace(0,voxel_size[1]*probe.shape[1]*torch.tan(torch.deg2rad(torch.tensor(inc_angle))),probe.shape[1])\n",
    "        \n",
    "        PhaserampmatY, _ = torch.meshgrid(-phase_gradient_Y,phase_gradient_X)\n",
    "\n",
    "        probe_amp = torch.abs(probe)\n",
    "        probe_phase = torch.angle(probe)\n",
    "        \n",
    "        tilted_probe = probe_amp * torch.exp(1j*(probe_phase-(2*torch.pi*(PhaserampmatY/lambda_val))))\n",
    "        \n",
    "        return tilted_probe\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e9359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_3d_tensor(A,structure_height,oversample_structure,oversample_factor):\n",
    "\n",
    "    # Get the dimensions of the 2D tensor\n",
    "    width,height = A.shape\n",
    "    output3d = A.repeat(structure_height,1,1)-torch.arange(structure_height).unsqueeze(1).unsqueeze(1).expand(structure_height,width,height)\n",
    "    output3d = torch.clamp(output3d,0,1)\n",
    "    if oversample_structure == True and oversample_factor !=1:\n",
    "        weight = torch.ones(1,1,1,1,oversample_factor)/oversample_factor\n",
    "    \n",
    "        output3d = torch.nn.functional.conv3d(output3d.unsqueeze(0).unsqueeze(0), weight, stride=(1,1,oversample_factor), padding=0, dilation=1, groups=1).squeeze()\n",
    "\n",
    "    if not output3d.size(1) == params_size[1]:\n",
    "        sd = output3d.size(1) - params_size[1]\n",
    "        if sd > 0:\n",
    "            output3d = output3d[:,:-int(sd),:]\n",
    "        if sd < 0:\n",
    "            output3d = torch.nn.functional.interpolate(output3d.unsqueeze(0).unsqueeze(0), size=params_size, mode='trilinear').squeeze()\n",
    "    \n",
    "    return output3d.flip(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e3236e-0df1-4318-beff-4e32fb460ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba864b7-f088-4fa7-b3a9-bdd704695700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_3d_tensor(A,structure_height,oversample_structure,oversample_factor):\n",
    "\n",
    "    if oversample_structure == True:\n",
    "        # weight = torch.ones(1,1,1,1,oversample_factor)/oversample_factor\n",
    "    \n",
    "        # output3d = torch.nn.functional.conv3d(A.unsqueeze(0).unsqueeze(0), weight, stride=(1,1,oversample_factor), padding=0, dilation=1, groups=1).squeeze()\n",
    "        output3d = A # pooler3d = torch.nn.AvgPool1d(kernel_size=(oversample_factor))\n",
    "        # output3d = pooler3d(output3d)\n",
    "    if not output3d.size(1) == params_size[1]:\n",
    "        sd = output3d.size(1) - params_size[1]\n",
    "        if sd > 0:\n",
    "            output3d = output3d[:,:-int(sd),:]\n",
    "        if sd < 0:\n",
    "            output3d = torch.nn.functional.interpolate(output3d.unsqueeze(0).unsqueeze(0), size=params_size, mode='trilinear').squeeze()\n",
    "    \n",
    "    return output3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8090a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maximum_propdist(full_sim_size,voxel_size,lambda_val):\n",
    "    Propagator_wave_dim = full_sim_size[0:2]\n",
    "    propagator_wave_size = torch.tensor(Propagator_wave_dim) * torch.tensor(voxel_size)\n",
    "    dist_picker_r = Propagator_wave_dim[0] * (voxel_size[0])**2 / lambda_val\n",
    "    dist_picker_c = Propagator_wave_dim[1] * (voxel_size[1])**2 / lambda_val\n",
    "    \n",
    "    print('the maximum prop dist for these params =',\"%5.5E\" % (dist_picker_r),'m')\n",
    "    \n",
    "def get_maximum_propdist2(delta_res,lambda_val):\n",
    "    z = (0.32 * (delta_res)**2) / lambda_val\n",
    "    print('the maximum prop dist for these params =',\"%5.5E\" % (z),'m')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c9d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flux_rescale(probe_in, flux_in): \n",
    "    current_flux = torch.sum(torch.abs(probe_in) ** 2)\n",
    "    flux_rescale_factor = flux_in / current_flux\n",
    "    probe_out = (flux_rescale_factor)**2 * torch.abs(probe_in) * (torch.cos(torch.angle(probe_in)) + 1j * torch.sin(torch.angle(probe_in)))\n",
    "    return probe_out\n",
    "def retain_flux(previous_amp,previous_phase, current_amp, current_phase):\n",
    "    current_probe = current_amp * torch.exp(1j*current_phase)\n",
    "    previous_probe = previous_amp * torch.exp(1j*previous_phase)\n",
    "    current_flux = torch.sum(torch.abs(current_probe) ** 2)\n",
    "    previous_flux = torch.sum(torch.abs(previous_probe) ** 2)\n",
    "    flux_rescale_factor = current_flux / previous_flux\n",
    "    current_probe_rescaled  = (flux_rescale_factor)**2 * torch.abs(current_probe) * (torch.cos(torch.angle(current_probe)) + 1j * torch.sin(torch.angle(current_probe)))\n",
    "    amp = torch.abs(current_probe_rescaled)\n",
    "    phase = torch.angle(current_probe_rescaled)\n",
    "    \n",
    "    return amp, phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4885ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prop_mask(inputwave,rad,blur,aspr):\n",
    "    if type(aspr) == torch.Tensor:\n",
    "        aspr = aspr.cpu().numpy()\n",
    "        \n",
    "    inputsize = inputwave.size()\n",
    "    propmaskinit = np.zeros(inputsize)\n",
    "    mask_size = inputsize\n",
    "\n",
    "    # Create a grid of coordinates\n",
    "    x, y = np.meshgrid(np.arange(mask_size[1])-mask_size[1]/2, (np.arange(mask_size[0])-mask_size[0]/2))\n",
    "\n",
    "    # Calculate the distance from the center of the circle\n",
    "    distance = np.sqrt((x)**2 + (y/aspr)**2)\n",
    "\n",
    "    # Create a binary circle mask\n",
    "    circle_mask = np.where(distance <= rad, 1, 0)\n",
    "    circle_mask = circle_mask.astype(float)\n",
    "    # propmaskinit[30:-30,30:-30] = 1\n",
    "    sigma = blur\n",
    "    propmask_b = torch.tensor(gaussian_filter(circle_mask,sigma)).to(torch.float32)\n",
    "\n",
    "    # propmask_b = torch.tensor(circle_mask).to(torch.float32)\n",
    "\n",
    "    propmask_b[propmask_b>1] = 1\n",
    "    return propmask_b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c50962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_modelprobe(propdist,lambda_val,voxel_size,grid_shape):\n",
    "    u,v = create_freq_mesh(voxel_size,grid_shape)\n",
    "    u = u/voxel_size[0]\n",
    "    v = v/voxel_size[1]\n",
    "    H = torch.exp(-1j*torch.pi*lambda_val*propdist*(u**2+v**2))\n",
    "    return H\n",
    "\n",
    "    \n",
    "def make_csaxs_model_probe(wavelength,probe_dims,desired_pixel_size,\n",
    "                           probe_diameter,central_stop_diameter,zone_plate_diameter,\n",
    "                          outer_zone_width,prop_dist):\n",
    "    \n",
    "    zp_f = zone_plate_diameter*outer_zone_width/wavelength\n",
    "#     print(\"zp_f:\", zp_f)\n",
    "    upsample = 10\n",
    "    voxel_ratio = desired_pixel_size[1]/desired_pixel_size[0]\n",
    "    \n",
    "    \n",
    "    defocus = prop_dist\n",
    "    Nprobe = upsample*torch.tensor(probe_dims)\n",
    "    padsize = int(((Nprobe[0]*(voxel_ratio-1))/2))\n",
    "#     print(\"guessed pad:\", padsize)\n",
    "#     print(\"desired pixel size before psi rando trans\",desired_pixel_size)\n",
    "    desired_pixel_size = (zp_f + defocus) * wavelength / (Nprobe*desired_pixel_size)\n",
    "#     print(\"desired pixel size after psi rando trans\",desired_pixel_size)\n",
    "    r1_pix = probe_diameter/desired_pixel_size\n",
    "#     print(r1_pix)\n",
    "    r2_pix = central_stop_diameter/desired_pixel_size\n",
    "    xvec = torch.arange(-Nprobe[1]/2,torch.floor((Nprobe[1]-1)/2))\n",
    "    yvec = torch.arange(-Nprobe[1]/2,torch.floor((Nprobe[1]-1)/2))\n",
    "    x,y = torch.meshgrid(xvec,yvec)\n",
    "    r2 = (x*desired_pixel_size[1])**2+(y*desired_pixel_size[1])**2\n",
    "    w = make_prop_mask(r2,(r1_pix[1]/2).cpu().numpy(),0.1,1)\n",
    "    w += -make_prop_mask(r2,(r2_pix[1]/2).cpu().numpy(),0.1,1)\n",
    "    tf = torch.exp(-1j*torch.pi*(r2)/(wavelength*zp_f))\n",
    "    wc = w*tf\n",
    "#     probe_hr1 = farfield_PSI_prop(wc,wavelength,zp_f+defocus,desired_pixel_size)\n",
    "    \n",
    "    N = Nprobe\n",
    "    \n",
    "    wcp = torch.nn.functional.pad(wc,(0,0,padsize,padsize),mode='constant',value=0)\n",
    "    r2p = torch.nn.functional.pad(r2,(0,0,padsize,padsize),mode='constant',value=0)\n",
    "    propdist = (zp_f+defocus)\n",
    "    probe_hr1 = -1j * (torch.exp(1j * torch.pi * lambda_val * propdist * r2p / (N[0]*N[1])) \n",
    "                       * torch.fft.ifftshift(torch.fft.fft2(torch.fft.fftshift(\n",
    "                           wcp * torch.exp(1j * torch.pi * r2p / (lambda_val*propdist))))))\n",
    "    \n",
    "    \n",
    "    phrs = torch.tensor((probe_hr1.size(0)/2,probe_hr1.size(1)/2))\n",
    "    cropinds = (int(float(phrs[0])-float((probe_dims[0]+padsize*2/upsample)/2)),\n",
    "                int(float(phrs[0])+float((probe_dims[0]+padsize*2/upsample)/2)),\n",
    "                int(float(phrs[1])-float((probe_dims[1])/2)),\n",
    "                int(float(phrs[1])+float((probe_dims[1])/2)),\n",
    "               )\n",
    "#     print(cropinds)\n",
    "    model_probe1 = probe_hr1[cropinds[0]:cropinds[1],cropinds[2]:cropinds[3]]\n",
    "    return model_probe1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920ee226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probe_subpixel_shift(inputprobe,shift_amount_vert,shift_amount_hor,slab_thickness,y_voxel_size):\n",
    "    \n",
    "    # the amount of y shift corresponds to 1 pixel \n",
    "    # up or down is 1 slice further or closer along the z direction.\n",
    "    #so if we wish to shift by 500nm and hte slab thickness is 1000nm, the corresponding shift is 0.5 pixels.\n",
    "    shift_amount_pixelsv = shift_amount_vert \n",
    "    shift_amount_normalisedv = shift_amount_pixelsv / (inputprobe.size(0)*0.5)\n",
    "    shift_amount_pixelsh = shift_amount_hor \n",
    "    shift_amount_normalisedh = shift_amount_pixelsh / (inputprobe.size(1)*0.5)\n",
    "    \n",
    "    input_tensor = torch.zeros(1,2,inputprobe.size(0),inputprobe.size(1))\n",
    "    input_tensor[:,0,:,:] = torch.real(inputprobe) \n",
    "    input_tensor[:,1,:,:] = torch.imag(inputprobe)\n",
    "    \n",
    "    inputsize = input_tensor.size()\n",
    "#     print(inputsize)\n",
    "    grid = torch.zeros(inputsize[0],inputsize[2],inputsize[3],2)\n",
    "    new_y  = torch.linspace(-1,1,inputprobe.size(0)) + shift_amount_normalisedv\n",
    "    new_x  = torch.linspace(-1,1,inputprobe.size(1)) + shift_amount_normalisedh\n",
    "    newx_mesh,newy_mesh = torch.meshgrid(new_y,new_x)\n",
    "    grid[:,:,:,0] = newy_mesh\n",
    "    grid[:,:,:,1] = newx_mesh\n",
    "    output = torch.nn.functional.grid_sample(input_tensor,grid,align_corners=True,mode=\"bilinear\").squeeze()\n",
    "    output_complex = (output[0,:,:] + 1j*output[1,:,:]).to(torch.complex64)\n",
    "#     print(output_complex.size())\n",
    "    return output_complex\n",
    "def probe_subpixel_shift_fourier(inputprobe,shift_amount_vert,shift_amount_hor,slab_thickness,voxel_size,hx_shift=0,hz_shift=0):\n",
    "    probe_F = torch.fft.fft2(inputprobe)\n",
    "    xx,yy = create_freq_mesh(voxel_size,probe_F.size())\n",
    "    m1 = torch.exp(-1j*2*torch.pi*(xx*(shift_amount_hor+hx_shift)+yy*(shift_amount_vert+hz_shift)))\n",
    "    # print(torch.sum(torch.isnan(m1)))\n",
    "    probe_shifted = torch.fft.ifft2(probe_F*m1)\n",
    "    return probe_shifted\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220706c2-7dda-4fc7-bbbd-ac73898ccadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_0_1(input):\n",
    "    imin = torch.min(input)\n",
    "    imax = torch.max(input-imin)\n",
    "    if imax == 0:\n",
    "        output = input\n",
    "    else:    \n",
    "        output = (input-imin)/(imax)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb258fb-8cad-46c9-aadb-d1d8379094d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_memcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ceff4a-3022-4f60-9dff-408d0b03ff35",
   "metadata": {},
   "source": [
    "## Load scan positions, define ROI of scans, and specify incidence angle:\n",
    "### An incidence angle must be defined for each subscan, even if they are the same.\n",
    "### This simulation script comes with a premade position and scan list (demo_pz_values.npy,demo_px_values.npy). You can modify it yourself, or load your own one in as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc8e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(2)\n",
    "file_paths = [r'blank']\n",
    "\n",
    "all_px_values = []\n",
    "all_pz_values = []\n",
    "all_ROIlist = []\n",
    "all_ROI_inds = []\n",
    "full_scan_identifier_list = []\n",
    "# Loop over the list of file paths\n",
    "file_iter = 0\n",
    "n_sub_scans = 1 #load this number of sub scans iwthin a scan\n",
    "dataset_shape = np.zeros(len(file_paths)*n_sub_scans)\n",
    "all_pz_values = np.load(\"demo_pz_values.npy\")\n",
    "all_px_values = np.load(\"demo_px_values.npy\")\n",
    "for file_path in file_paths:\n",
    "\n",
    "            full_scan_identifier_list += [file_iter]*all_pz_values.shape[1]\n",
    "            \n",
    "            print(\"subscan\",file_iter, \"loaded\")\n",
    "            file_iter = file_iter + 1\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# all_pz_values *= 0.6\n",
    "# Calculate ROIlist as in your code\n",
    "px_block = [5,25] \n",
    "ROI_inds = np.where((all_px_values < px_block[1]) & (all_px_values > px_block[0]) & (all_pz_values < 105) & (all_pz_values > 25) | #Keep at 65, 35!!\n",
    "                    (all_px_values < px_block[1]) & (all_px_values > px_block[0]) & (all_pz_values < 0) & (all_pz_values > 0) |\n",
    "                   \n",
    "                    (all_px_values < px_block[1]) & (all_px_values > px_block[0]) & (all_pz_values < 0) & (all_pz_values > 0)) \n",
    "\n",
    "cvals = np.zeros((1,all_px_values.shape[1]))\n",
    "\n",
    "cvals[0][ROI_inds[1]] = 1\n",
    "print(\"size of scans in ROI:\",all_px_values[ROI_inds].size)\n",
    "\n",
    "scan_categories = np.cumsum(dataset_shape)\n",
    "print(\"scan_categories\",scan_categories)\n",
    "\n",
    "#which subset is a list where each value is each file it belongs to.\n",
    "which_subset = np.digitize(ROI_inds[1],scan_categories)\n",
    "\n",
    "#this corrects the scan number by subtracging the previous number of scans from ecah scan, since each subscan starts from zero... \n",
    "#this is to correctly load the h5 with teh correct indices.\n",
    "scan_no_corrector = np.zeros_like(which_subset)\n",
    "\n",
    "sc2 = np.insert(scan_categories,0,0)[:-1]\n",
    "# for n1 in range(1,(which_subset.shape[0])):\n",
    "#     scan_no_corrector[n1] = sc2[which_subset[n1]]#-sc2[which_subset[n1]]\n",
    "#some bug?\n",
    "scan_no_corrector[0] = scan_no_corrector[1]\n",
    "\n",
    "corrected_ROI_inds = (ROI_inds[1]-scan_no_corrector)\n",
    "\n",
    "ROI_inds_sub = [[] for _ in range(len(file_paths)*n_sub_scans)]\n",
    "for ii in range(len(file_paths)*n_sub_scans):\n",
    "    ROI_inds_sub[ii] = corrected_ROI_inds[which_subset==(ii)].astype(int).tolist()\n",
    "\n",
    "num_scans = all_px_values[ROI_inds].size\n",
    "\n",
    "\n",
    "scan_inc_angle_index = [0.7]\n",
    "for ii in range(len(ROI_inds_sub)):\n",
    "    \n",
    "    if ii == 0:\n",
    "        inc_angle_list = np.ones(len(ROI_inds[1]))*scan_inc_angle_index[ii]\n",
    "        \n",
    "        scan_identifier_list = np.ones(len(ROI_inds[1]))*ii\n",
    "    else:\n",
    "        inc_angle_list = np.concatenate((inc_angle_list,np.ones(len(ROI_inds_sub[ii]))*scan_inc_angle_index[ii]))\n",
    "        scan_identifier_list = np.concatenate((scan_identifier_list,np.ones(len(ROI_inds_sub[ii]))*ii))\n",
    "\n",
    "#fix inc angles list \n",
    "\n",
    "\n",
    "colors = []\n",
    "for val in cvals[0]:\n",
    "    \n",
    "    if val == 1:\n",
    "        colors.append('red')\n",
    "    else: \n",
    "        colors.append('blue')\n",
    "markers_list = ['x' if value == 0 else 'x' for value in full_scan_identifier_list]\n",
    "# Define a mapping from scan identifiers to color transformations\n",
    "color_table = {\n",
    "    0: {'blue': 'mediumblue', 'red': 'cornflowerblue'},\n",
    "    1: {'blue': 'mediumblue', 'red': 'lightsteelblue'},\n",
    "    2: {'blue': 'mediumblue', 'red': 'fuchsia'},\n",
    "    3: {'blue': 'darkviolet', 'red': 'deeppink'},\n",
    "    4: {'blue': 'darkviolet', 'red': 'hotpink'},\n",
    "    5: {'blue': 'darkviolet', 'red': 'gold'},\n",
    "    7: {'blue': 'darkred', 'red': 'tomato'},\n",
    "    7: {'blue': 'darkred', 'red': 'orangered'},\n",
    "    8: {'blue': 'darkred', 'red': 'coral'},\n",
    "    9: {'blue': 'darkolivegreen', 'red': 'springgreen'},\n",
    "    10: {'blue': 'darkolivegreen', 'red': 'limegreen'},\n",
    "    11: {'blue': 'darkolivegreen', 'red': 'palegreen'},\n",
    "}\n",
    "\n",
    "# Iterate through each index and update colors based on full_scan_identifier_list\n",
    "for ii in range(len(full_scan_identifier_list)):\n",
    "    scan_id = full_scan_identifier_list[ii]\n",
    "    if scan_id in color_table:\n",
    "        current_color = colors[ii]\n",
    "        if current_color in color_table[scan_id]:\n",
    "            colors[ii] = color_table[scan_id][current_color]\n",
    "\n",
    "plt.figure(figsize=[15,10])\n",
    "for apx, apz, color,marks in zip(all_px_values[0], all_pz_values[0], colors,markers_list):\n",
    "    plt.scatter(apx, apz, c=color, s=70,marker=marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533e5909-d824-49a0-9bf8-7ca68c9a8347",
   "metadata": {},
   "source": [
    "## Convert scan positions into voxel positions. \n",
    "### This includes discretization to the nearest voxel. Discretization errors are compensated in the simulation through probe shifts, which are also calculated. \n",
    "#### Scan/probe positions are optimized during reconstruction according to their learning rate. Set learning rate to 0 to disable this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d09c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_scans = len(ROI_inds[0])\n",
    "print(\"num scans in this sim\",num_scans)\n",
    "\n",
    "scan_size_y = params_size[1]\n",
    "scan_size_z = params_size[2]\n",
    "\n",
    "#visualise where the scans are.\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "\n",
    "#in the case we load a custom subset:\n",
    "px_voxels = (all_px_values[ROI_inds]*1e-6) / voxel_size[1].cpu().numpy()\n",
    "pz_voxels = (all_pz_values[ROI_inds]*1e-6) / slab_thickness.cpu().numpy()\n",
    "px_voxels = px_voxels.reshape(-1,1) \n",
    "pz_voxels = pz_voxels.reshape(-1,1) \n",
    "#add the minimum so that we only have positive numbers. Also add half the sim size so that the final scans are not cut off.\n",
    "if np.min(px_voxels) < 0:\n",
    "    px_voxels += np.round(abs(np.min(px_voxels))+scan_size_y/2)\n",
    "\n",
    "elif np.min(px_voxels) >= 0:\n",
    "    px_voxels -= np.round(abs(np.min(px_voxels))-scan_size_y/2)\n",
    "    \n",
    "if np.min(pz_voxels) < 0:\n",
    "    pz_voxels += np.round(abs(np.min(pz_voxels))+scan_size_z/2)\n",
    "elif np.min(pz_voxels) >= 0:\n",
    "    pz_voxels -= np.round(abs(np.min(pz_voxels))-scan_size_z/2)\n",
    "# #check it makes sense\n",
    "# plt.scatter(px_voxels,pz_voxels)\n",
    "# plt.scatter(np.round(px_voxels,decimals=0),np.round(pz_voxels,decimals=0))\n",
    "\n",
    "# plt.xlabel(\"voxel position (X)\")\n",
    "# plt.ylabel(r\"voxel position (Z) (beamdir $\\rightarrow$)\")\n",
    "\n",
    "#caluclate the subpixelshifts\n",
    "subpixel_shifts_z =  -torch.tensor((np.round(pz_voxels,decimals=0) - pz_voxels))\n",
    "subpixel_shifts_y =  torch.tensor((np.round(px_voxels,decimals=0) - px_voxels))\n",
    "\n",
    "\n",
    "#now create zposindex and yposindex.\n",
    "#note 21 03 24: we  add a +1 to everything so that no indices are zero, this helps if oversampling is used.\n",
    "zposindex = []\n",
    "for i in range(num_scans):\n",
    "    zposindex.append((int(np.round(pz_voxels[i]-scan_size_z/2)+1),int(np.round(pz_voxels[i]+scan_size_z/2+1)+1)))\n",
    "yposindex = []\n",
    "for i in range(num_scans):\n",
    "    yposindex.append((int(np.round(px_voxels[i]-scan_size_y/2)+1),int(np.round(px_voxels[i]+scan_size_y/2+1)+1)))\n",
    "\n",
    "# plt.figure()\n",
    "# plt.subplot(2,1,1)\n",
    "# plt.plot((subpixel_shifts_z).cpu())\n",
    "# plt.title(\"subpixel shifts Z\")\n",
    "# plt.subplot(2,1,2)\n",
    "# plt.plot((subpixel_shifts_y).cpu())\n",
    "# plt.title(\"subpixel shifts Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b13dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_sim_size_zdir = max(max(zposindex))\n",
    "full_sim_size_ydir = max(max(yposindex))\n",
    "\n",
    "xr_z_size = int(full_sim_size_zdir/1)\n",
    "print(\"size of all sims [y,z],\",full_sim_size_ydir,full_sim_size_zdir)\n",
    "downscaling_factor_z = (full_sim_size_zdir/xr_z_size)\n",
    "print(\"downscaling factor z (number of slices 1 z voxel represents):\" ,downscaling_factor_z)\n",
    "#so here we use this to convert the z indices\n",
    "z_indices_downscaled = zposindex\n",
    "new_zposindex = [(int(x / downscaling_factor_z), int(y / downscaling_factor_z)) for x, y in zposindex]\n",
    "# print(new_zposindex)\n",
    "\n",
    "xr_y_size = int(full_sim_size_ydir/1)\n",
    "# print(\"size of all sims [y,z],\",full_sim_size_ydir,full_sim_size_zdir)\n",
    "downscaling_factor_y = (full_sim_size_ydir/xr_y_size)\n",
    "print(\"downscaling factor y (number of slices 1 y voxel represents):\" ,downscaling_factor_y)\n",
    "#so here we use this to convert the z indices\n",
    "y_indices_downscaled = yposindex\n",
    "new_yposindex = [(int(x / downscaling_factor_y), int(y / downscaling_factor_y)) for x, y in yposindex]\n",
    "# print(new_yposindex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb50424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tilted plane correction has not been fully implemented, but was shown not to make a significant difference in testing. For now set to false :\n",
    "do_tilted_plane_corr = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ea8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make masks\n",
    "# detector_mask_crop = detector_mask_crop[wind1[0]:wind1[1],wind1[2]:wind1[3]]\n",
    "num_scans1 = num_scans\n",
    "# num_scans2 = len(ROI_inds_sub[1])\n",
    "# num_scans3 = len(ROI_inds_sub[2])\n",
    "plt.figure(figsize=[10,10])\n",
    "# print(\"total scans of all angles\",num_scans1+num_scans2)\n",
    "# print(\"scan crossover points\",num_scans1,num_scans1+num_scans2)\n",
    "GT = torch.zeros((crop_window_size[0],crop_window_size[1],num_scans))\n",
    "\n",
    "if do_tilted_plane_corr == 0:\n",
    "\n",
    "    mask = torch.ones_like(GT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d1f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign GT\n",
    "GT_out_pack = GT\n",
    "print(\"Size of GT exit waves:\",GT_out_pack.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62385fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress_bar(iteration, total, bar_length=20):\n",
    "    progress = (iteration / total)\n",
    "    arrow = '=' * int(round(bar_length * progress))\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "    sys.stdout.write(f'\\rthis iter progress: [{arrow + spaces}] {int(progress * 100)}%')\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e4d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_probe_test(probe_in, blur_strength_x, blur_strength_y):\n",
    "    \n",
    "    probe_in_R = torch.real(probe_in).cpu().numpy()\n",
    "    probe_in_I = torch.imag(probe_in).cpu().numpy()\n",
    "    BPR = torch.tensor(gaussian_filter(probe_in_R,(blur_strength_x,blur_strength_y))).to(torch.float32)\n",
    "    BPI = torch.tensor(gaussian_filter(probe_in_I,(blur_strength_x,blur_strength_y))).to(torch.float32)\n",
    "    blurred_probe = BPR+1j*BPI\n",
    "    \n",
    "    return blurred_probe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc084399-09f5-4793-aac8-d9714b640a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_model_probe = True\n",
    "n_probe_modes = int(np.max(scan_identifier_list+1))\n",
    "model_probe_pixel_size = voxel_size#torch.tensor((4.4570e-08,4.4570e-08))#torch.zeros(n_probe_modes,2)\n",
    "probe_xvoxelsizes = torch.linspace(7e-9,7e-9,n_probe_modes) \n",
    "rolls = torch.linspace(0,0,n_probe_modes)\n",
    "pretiltangles = torch.linspace(0,0,n_probe_modes)\n",
    "\n",
    "new_flux = 4.0e-8\n",
    "probe_vmax = 8e-4\n",
    "probe_aspr = voxel_size[0]/voxel_size[1]\n",
    "recon_FFT_vmin = -5\n",
    "recon_FFT_vmax = 0\n",
    "new_prop = -8.5e-4#-13.5e-4 best for 06deg,07deg, -10e-4 beter for 09deg\n",
    "probepad = 400\n",
    "\n",
    "initprobesize = [182,182]\n",
    "cd1 = int((initprobesize[0]-crop_window_size[1])/2)\n",
    "probecenter=None\n",
    "probesigma_x=30.0\n",
    "probesigma_y=100.0\n",
    "\n",
    "if use_model_probe == True:\n",
    "    probe_diameter = 240e-6 #240e-6             #170e-6 #240e-6   #300e-6\n",
    "    central_stop_diameter = 48e-6#45e-6    #55e-6\n",
    "    zone_plate_diameter = 490e-6#330e-6           #200e-6   #330e-6\n",
    "    outer_zone_width = 43e-9#90e-9           #55e-9   #70e-9\n",
    "    # init_model_probe = make_gauss_model_probe(initprobesize[1]*int(voxel_size[1]/voxel_size[0]),initprobesize[1],probecenter,probesigma_x,probesigma_y)\n",
    "    init_model_probe = make_csaxs_model_probe(lambda_val,initprobesize,model_probe_pixel_size,\n",
    "                           probe_diameter,central_stop_diameter,zone_plate_diameter,\n",
    "                         outer_zone_width,new_prop)\n",
    "    init_model_probe = optimise_probe_prop(torch.nn.functional.pad(init_model_probe,(probepad,probepad,probepad,probepad)),new_prop,lambda_val,model_probe_pixel_size)[probepad:-probepad,probepad:-probepad]*new_flux\n",
    "    model_probes = torch.zeros(init_model_probe.size(0),init_model_probe.size(1),n_probe_modes,dtype=torch.complex64)\n",
    "    model_probes[:,:,0] = init_model_probe #first one is always voxel size\n",
    "    for n1 in range(0,n_probe_modes):\n",
    "        print(\"probe mode:\",n1)\n",
    "        # this_model_probe = make_gauss_model_probe(initprobesize[1]*int(voxel_size[1]/voxel_size[0]),initprobesize[1],probecenter,probesigma_x,probesigma_y)\n",
    "        this_model_probe = make_csaxs_model_probe(lambda_val,initprobesize,model_probe_pixel_size,\n",
    "                               probe_diameter,central_stop_diameter,zone_plate_diameter,\n",
    "                             outer_zone_width,new_prop)\n",
    "        newsd = int((init_model_probe.size(0)-this_model_probe.size(0))/2)\n",
    "        \n",
    "        this_model_probe = torch.nn.functional.pad(this_model_probe,(0,0,newsd,newsd),value=0)\n",
    "        if this_model_probe.size() != model_probes[:,:,n1].size():\n",
    "            this_model_probe = torch.nn.functional.pad(this_model_probe,(0,0,0,1),value=0)\n",
    "            \n",
    "            \n",
    "        this_model_probe = optimise_probe_prop(torch.nn.functional.pad(this_model_probe,(probepad,probepad,probepad,probepad)),new_prop,lambda_val,model_probe_pixel_size)[probepad:-probepad,probepad:-probepad]\n",
    "        # this_model_probe[-200:,:] = init_model_probe[-200:,:] \n",
    "        this_model_probe = torch.roll(this_model_probe,int(rolls[n1]),0)*new_flux\n",
    "        model_probes[:,:,n1] = this_model_probe#probe_tilt_gradient(this_model_probe,pretiltangles[n1],voxel_size,slab_thickness)\n",
    "    \n",
    "    orig_csaxs_probe = ((init_model_probe) * new_flux)\n",
    "    print(\"using model probe, with dimensions of\", init_model_probe.size())\n",
    "else:\n",
    "    probe_pixel_size = recon_probe_pixel_size\n",
    "    orig_csaxs_probe = (new_probe_T)\n",
    "\n",
    "plt.figure(figsize=[5,5])\n",
    "plt.imshow(torch.abs(model_probes[:,:,0]).cpu(),aspect=probe_aspr,vmin=0,vmax=probe_vmax), plt.colorbar()\n",
    "plt.title(\"input probe for sim\")\n",
    "plt.figure(figsize=[5,10])\n",
    "for n1 in range(n_probe_modes):\n",
    "    plt.subplot(5,4,n1+1)\n",
    "    plt.imshow(torch.abs(model_probes[:,:,n1]).cpu(),aspect=probe_aspr,vmin=0,vmax=probe_vmax), plt.colorbar()\n",
    "    plt.title(f\"Probe Mode {n1}\")\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "\n",
    "this_exit_wave_crop = v2.CenterCrop(size=(crop_window_size))(torch.abs(torch.fft.fftshift(torch.fft.fft2((model_probes[:,:,0]))))+1e-20)\n",
    "plt.imshow(torch.log(this_exit_wave_crop).cpu(),aspect=1)\n",
    "plt.title(\"FFT of input probe\")\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plt.imshow(torch.log(torch.abs(GT[:,:,5]**0.5)+1e-10).cpu(),vmin=recon_FFT_vmin,vmax=recon_FFT_vmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f7ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def combine_probe_modes(multimode_probe_in,scan_number):\n",
    "    if probe_is_FFT == True:\n",
    "            multimode_probe_in = torch.fft.ifft2(torch.fft.fftshift(multimode_probe_in))\n",
    "        \n",
    "    if len(multimode_probe_in.size()) == 3:\n",
    "        combined_probes = multimode_probe_in[:,:,int(scan_identifier_list[scan_number])]\n",
    "    if len(multimode_probe_in.size()) == 2:\n",
    "        combined_probes = multimode_probe_in\n",
    "    return combined_probes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b271c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_second_mode(probe_in,pad1):\n",
    "    probeinR = torch.real(probe_in)\n",
    "    probeinI = torch.imag(probe_in)\n",
    "    probeinR = torch.nn.functional.pad(probeinR,(0,0,pad1,pad1))\n",
    "    probeinI = torch.nn.functional.pad(probeinI,(0,0,pad1,pad1))\n",
    "    probeinR = torch.nn.functional.interpolate(probeinR.unsqueeze(0).unsqueeze(0),size=probe_in.size()).squeeze()\n",
    "    probeinI = torch.nn.functional.interpolate(probeinI.unsqueeze(0).unsqueeze(0),size=probe_in.size()).squeeze()\n",
    "    probeout = probeinR + 1j* probeinI\n",
    "    return probeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc77cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_iso_random_initguess(xsize,ysize,zsize,aspr):\n",
    "    str1 = torch.rand(xsize,int(ysize/aspr),zsize)\n",
    "    str2 = torch.nn.functional.interpolate(str1.unsqueeze(0).unsqueeze(0),size=[xsize,ysize,zsize]).squeeze().unsqueeze(0)\n",
    "    str3 = torch.tensor(gaussian_filter(str2.cpu().numpy(),5)).to(torch.float32)\n",
    "    vec_X = torch.linspace(-2,2,str2.size(2))\n",
    "    vec_Y = torch.linspace(-2,2,str2.size(1))\n",
    "#testcurve_X = -2*(vec_X)**2+10\n",
    "    testcurve_Y = 5*(vec_Y)**2\n",
    "    test_structure_curve,_ = torch.meshgrid(testcurve_Y,vec_X)\n",
    "#     plt.imshow(test_structure_curve.cpu(),aspect=0.01)\n",
    "    \n",
    "    \n",
    "#     str3 += test_structure_curve\n",
    "    return str3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5936bd80",
   "metadata": {},
   "source": [
    "# This cell sets pytorch relevant initial parameters for the optimisaiton, and defines parameter tensors, optimizers and learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29612b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"full area covered by optimizable volume:\", \"%5.5E\" % (slab_thickness*full_sim_size[2]*1e6), \"um\" )\n",
    "yzaspr = (slab_thickness*downscaling_factor_z)/(voxel_size[1]*downscaling_factor_y)\n",
    "volsizeratio = xr_z_size/xr_y_size\n",
    "xy_voxel_size_ratio = voxel_size[0]/voxel_size[1]\n",
    "print(\"params size\", params_size)\n",
    "\n",
    "using_n_scans_per_pixel = True\n",
    "# using_rprop = False\n",
    "do_gradient_accumulation = True\n",
    "#if loading a previously saved/optimised \n",
    "load_previous = False\n",
    "#this is whether TV is calculated ove rthe hwole volume or just over each scan. \n",
    "use_per_scan_TV = False\n",
    "use_support_mask = False\n",
    "use_multiple_probes = False\n",
    "use_building_blocks = False\n",
    "use_multiple_probe_modes = True\n",
    "use_noise = True\n",
    "optimize_scan_offsets = True\n",
    "probe_is_FFT = 0\n",
    "oversample_structure = True\n",
    "if using_n_scans_per_pixel == True and do_gradient_accumulation == False:\n",
    "    print(\"cannot have n_scans_per_pixel div if gradient accumulation is not used, setting ot true\")\n",
    "    do_gradient_accumulation == True\n",
    "\n",
    "if use_multiple_probe_modes == True:\n",
    "    print(\"using multiple probe modes\")\n",
    "\n",
    "    probe_in = model_probes.clone()\n",
    "\n",
    "else:\n",
    "    print(\"not using multiple probe modes\")\n",
    "\n",
    "    \n",
    "probe_prop_amt = torch.nn.Parameter(torch.tensor(1e-5))\n",
    "probefluxmult = torch.nn.Parameter(torch.tensor(1,dtype=torch.float32)) #6e2 for scan 509\n",
    "\n",
    "if load_previous:\n",
    "    probes_presave = torch.load('/home/lubs/pytorchnotebooks/Au_realdatatensor_probes_050608_conv_27-11-2024.pt')\n",
    "    # probe_in = torch.nn.Parameter(probes_presave)\n",
    "    probes_param = torch.nn.Parameter(probes_presave)\n",
    "else:\n",
    "    if probe_is_FFT == True:\n",
    "        probes_param = torch.nn.Parameter(torch.fft.fftshift(torch.fft.fft2(probe_in)))\n",
    "    else:\n",
    "        probes_param = torch.nn.Parameter(probe_in)\n",
    "\n",
    "if use_building_blocks == True:\n",
    "    xr_x_size = 1 #must be 1 for building blocks.\n",
    "else:\n",
    "    xr_x_size = 1#params_size[0]\n",
    "# support_maskC_bin3d = (~support_maskC_bin).repeat(xr_x_size,1,1)\n",
    "\n",
    "#the slice you can use to watch the recon. not always 0, but usually.\n",
    "viewing_slice = 5\n",
    "\n",
    "\n",
    "yzpad = 0\n",
    "print(\"final param size for this sim:\", xr_x_size,xr_y_size+yzpad*2,xr_z_size+yzpad*2)\n",
    "\n",
    "init_xr_scaling_factor = 0.02\n",
    "init_xr_substrateamt = 0.00\n",
    "init_xr_learning_rate = 1e5#30e-1\n",
    "grads_target = 0.2\n",
    "if optimize_scan_offsets == True:\n",
    "    subpixel_shifts_z = torch.nn.Parameter(-((torch.tensor((np.round(pz_voxels,decimals=0) - pz_voxels))*voxel_size[0])).clone())\n",
    "    subpixel_shifts_y = torch.nn.Parameter((torch.tensor((np.round(px_voxels,decimals=0) - px_voxels))*voxel_size[1]).clone())\n",
    "    hx_shift = torch.nn.Parameter(torch.rand(n_probe_modes)*1e-13)\n",
    "    hz_shift = torch.nn.Parameter(torch.rand(n_probe_modes)*1e-13)\n",
    "    scan_positions_optim = torch.optim.SGD([{'params': [subpixel_shifts_z,subpixel_shifts_y], 'lr': 1e-15},{'params': [hx_shift], 'lr': 5e-15},{'params': [hz_shift], 'lr': 5e-15}])\n",
    "    print(\"position optimization on\")\n",
    "\n",
    "\n",
    "# if load_previous == True:\n",
    "    \n",
    "#     pre_xr = torch.load('/home/lubs/pytorchnotebooks/Au_realdatatensor_0506deg_311024_conv.pt').detach() #this file had oversample factor 2 !!!\n",
    "#     # substrate_mean = torch.mean(pre_xr[:,:,3500:4000])\n",
    "#     # # pre_xr[:,:,:500] = 0\n",
    "#     # pre_xr -= substrate_mean\n",
    "#     pre_xr *= 12\n",
    "#     pre_xr = torch.clamp(pre_xr,0,4.1)\n",
    "    \n",
    "#     xr = torch.nn.Parameter(pre_xr)\n",
    "#     oversample_factor = 5\n",
    "\n",
    "# if not load_previous:\n",
    "if oversample_structure == True:\n",
    "    oversample_factor = 1\n",
    "    xr = torch.nn.Parameter(torch.rand(1,xr_y_size,xr_z_size*oversample_factor)*init_xr_scaling_factor+init_xr_substrateamt)#torch.nn.Parameter((create_iso_random_initguess(xr_x_size,xr_y_size+yzpad*2,(xr_z_size+yzpad*2)*oversample_factor,(yzaspr))*init_xr_scaling_factor+init_xr_substrateamt))\n",
    "else:\n",
    "    oversample_factor = 1\n",
    "    xr = torch.nn.Parameter((create_iso_random_initguess(xr_x_size,xr_y_size+yzpad*2,xr_z_size+yzpad*2,(yzaspr))*init_xr_scaling_factor+init_xr_substrateamt))\n",
    "\n",
    "\n",
    "if use_building_blocks != True:\n",
    "    n_scans_per_pixel = (torch.ones_like(xr))\n",
    "    #if youre using it or not:\n",
    "\n",
    "    for n1 in range(len(new_yposindex)):\n",
    "        n_scans_per_pixel[:,(new_yposindex[n1][0]+yzpad):(new_yposindex[n1][1]+yzpad),\n",
    "                          (new_zposindex[n1][0]+yzpad):(new_zposindex[n1][1]+yzpad)] += 1 \n",
    "\n",
    "    plt.imshow(n_scans_per_pixel[0,:,:].cpu()), plt.colorbar()\n",
    "\n",
    "    if using_n_scans_per_pixel:\n",
    "        print(\"using n scans per pixel\")\n",
    "    else:\n",
    "        print(\"not using n scans per pixel\")\n",
    "\n",
    "\n",
    "#model noise\n",
    "\n",
    "# noise_guess = torch.nn.Parameter(torch.clamp(torch.normal(torch.ones(crop_window_size[0],crop_window_size[1],num_scans)*noise_mean,torch.ones(crop_window_size[0],crop_window_size[1],num_scans)*noise_std),min=0))\n",
    "\n",
    "# Create an optimizer for the parameter xr #good lr is 2e-3!!\n",
    "#normal optim\n",
    "#are you doing gradient accumulation?\n",
    "if do_gradient_accumulation == True:\n",
    "    print('using gradient accumulation')\n",
    "else:\n",
    "    print('not using gradient accumulation')\n",
    "\n",
    "if use_per_scan_TV == True:\n",
    "    print('TV is calculated per scan area')\n",
    "else:\n",
    "    print('TV is calculated over entire volume')\n",
    "\n",
    "if use_support_mask == True:\n",
    "    print('support mask for grads is used')\n",
    "else:\n",
    "    print('support mask for grads is not used')\n",
    "if use_noise == 1:\n",
    "    print('using noise addition')\n",
    "else:\n",
    "    print('not using noise addition')\n",
    "\n",
    "#### Are you using rprop or Adam ?\n",
    "\n",
    "\n",
    "if do_gradient_accumulation == 0:\n",
    "    optimizer = torch.optim.RAdam([{'params': [xr], 'lr': init_xr_learning_rate,'weight_decay':0}])  # You can adjust the learning rate as needed    \n",
    "else:\n",
    "    optimizer = torch.optim.SGD([{'params': [xr], 'lr': init_xr_learning_rate,'weight_decay':0}])  # You can adjust the learning rate as needed    \n",
    "    optimizer_adam = torch.optim.Adam([{'params': [xr], 'lr': 8e-3,'weight_decay':0}])\n",
    "probe_params = [ {'params': [probes_param], 'lr': 5e-2, 'weight_decay': 1e-20}]\n",
    "probe_grads_target = 1.0e-8\n",
    "# noise_optim = torch.optim.RAdam([{'params': [noise_guess], 'lr': 5e-7}])  # You can adjust the learning rate as needed\n",
    "\n",
    "probe_optimizer = torch.optim.SGD(probe_params)\n",
    "#scheduler for probe\n",
    "probe_LR_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(probe_optimizer, mode='min', \n",
    "                    factor=0.5, patience=4, threshold=0.0001, threshold_mode='rel',\n",
    "                    cooldown=0, min_lr=0, eps=1e-07)\n",
    "\n",
    "prop_optim = torch.optim.RAdam([{'params': [probe_prop_amt], 'lr': 1e-4}]) #lr 5e-7 is agressive  # You can adjust the learning rate as needed\n",
    "num_iters = 50\n",
    "loss_tracker = np.zeros((num_iters,num_scans))\n",
    "total_sim_start_time = time.time()\n",
    "iters_out = torch.tensor([])\n",
    "dzz = 0\n",
    "dzy = 0\n",
    "tvx_alpha =  1e1*(xr_x_size*slab_thickness*downscaling_factor_z)/(params_size[0]*voxel_size[0]) #weight for TV in x direction\n",
    "print(\"tvx alpha\",tvx_alpha)\n",
    "tvy_alpha = 1#weight for TV in y direction\n",
    "print(\"tvy alpha\",tvy_alpha)\n",
    "tvz_alpha = 1 #weight for TV in z direction\n",
    "tvt_alpha = 3e-3 #total weight for all TV penalties  #if parial voxels, 1e-7 is typical, multiply by 1e6 or so if using complex\n",
    "\n",
    "probestart = 2 #iteration number at which the probe will begin optimising.\n",
    "tv_start = 2 #iteration number at which TV penalty will begin to apply.\n",
    "\n",
    "patience = 5\n",
    "divergence_count_start = 5\n",
    "divergence_thr = 2\n",
    "xrg = torch.zeros_like(xr)\n",
    "PFM = torch.zeros_like(probefluxmult)\n",
    "# orig_probe_max = torch.max(probe_amp)\n",
    "print(\"patience (number of iters before reducing LR):\",(divergence_thr+1))\n",
    "postresizeprobemask_rad = 95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a683d96-eaeb-41a4-ba70-6e71255d9beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if oversample_structure:\n",
    "    new_zposindex = [(int(x * oversample_factor), int(y * oversample_factor)) for x, y in zposindex]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c0863",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.cuda.empty_cache()\n",
    "optimizer.zero_grad()\n",
    "probe_optimizer.zero_grad()\n",
    "prop_optim.zero_grad()\n",
    "gc.collect()\n",
    "# if use_noise == 1:\n",
    "    # noise_optim.zero_grad()\n",
    "gpu_memcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6dcd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EWCI = [528,528,1,1] #EWCI = Exit Wave Crop Indices. Crop the exit wave of the simulation to match the size of the data. Useful when working with real experimental data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af59f50e-3920-4bf0-826d-8cbc0d902670",
   "metadata": {},
   "source": [
    "## Set additional simulation settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacea1f2-28c4-411e-8cec-9cdff0fb677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "substrate_layers = 200 #number of layers from the bottom upwards of substrate. This shuold be enough to fully reflect/absorb the incoming beam.\n",
    "probe_substrate_buffer = 2 #extra spacing between probe and substrate.\n",
    "top_buffer = 0 #add padding in the final multislice component if the beam reflects too early or too steeply.\n",
    "pre_prop_dist_multiplier = 1.5 #add extra propagation distance before the beam encounters the structure.\n",
    "post_prop_dist_multiplier = 1 #add extra propagation distance after the beam encounters the structure.\n",
    "test_inc_angle = 0.7 # the incidence angle to test out these settings.\n",
    "slab_pad_pre = 0 #add extra slices, not used, but necessary atm for code to run.\n",
    "slab_pad_post = 0 #add extra slices, not used , but necessary atm for code to run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790f5570-69fa-4827-9e31-6d9f9af14290",
   "metadata": {},
   "source": [
    "## Run a quick multislice forward simulation for diagnostic purposes.\n",
    "\n",
    "### Here you can check that the beam comes in, reflects, and exits, all within the space of the volume you defined.\n",
    "### this is a good point to check your simulation settings are okay, or if you need to go back and modify something, without having to run the entire reconstruction. It should only take a few seconds on a GPU\n",
    "#### The simulation follows this same code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de704636",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iii = 25\n",
    "with torch.no_grad():\n",
    "    \n",
    "    teststrin =  torch.zeros(params_size)\n",
    "        \n",
    "    probein = combine_probe_modes(probes_param,0) \n",
    "    probesize = probein.size()\n",
    "    pre_EW,pre_post_amt,probe_insertion_Y = MSForward_GI_SS_novol_partialvoxel_pre(\n",
    "                        torch.zeros(params_size),\n",
    "                        full_sim_size, params_size, voxel_size, slab_thickness,\n",
    "                        test_inc_angle, slab_pad_pre, slab_pad_post, probein,\n",
    "                        probe_buffer,1,0,substrate_layers,init_xr_substrateamt,0,0,0,0,0)\n",
    "    midEW,midslice,sideslice = MSForward_GI_SS_novol_partialvoxel_mid(teststrin,pre_EW,\n",
    "                   full_sim_size,params_size,voxel_size,slab_thickness,test_inc_angle,(substrate_layers))\n",
    "#     midEW*=make_probecut_mask(midEW,1,5e-1)\n",
    "    exit_wave = MSForward_GI_SS_novol_partialvoxel_post(xr,midEW,\n",
    "                    full_sim_size,params_size,voxel_size,slab_thickness,test_inc_angle,(substrate_layers),pre_post_amt,probe_insertion_Y,probesize,init_xr_substrateamt)\n",
    "#     F2 = torch.abs(farfield_PSI_prop(exit_wave,lambda_val,7.36e0,voxel_size))\n",
    "    F1 = torch.abs(torch.fft.fftshift(torch.fft.fft2(exit_wave)))\n",
    "    F1 = torch.nn.functional.interpolate(F1.unsqueeze(0).unsqueeze(0),size=(probesize),mode='bilinear').squeeze()\n",
    "#     F2 = torch.nn.functional.interpolate(F2.unsqueeze(0).unsqueeze(0),size=(probesize),mode='bilinear').squeeze()\n",
    "    F1 = (F1)[EWCI[0]:-EWCI[1],EWCI[2]:-EWCI[3]]\n",
    "#     F2 = (F2)[EWCI[0]:-EWCI[1],EWCI[2]:-EWCI[3]]\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=[15,10])\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.imshow(torch.abs(pre_EW).cpu(),aspect=0.1)\n",
    "    plt.title('|Input slice|')\n",
    "    plt.xlabel(\"y (voxels)\")\n",
    "    plt.ylabel(\"x (voxels)\")\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.imshow(torch.abs(midEW).cpu(),aspect=0.1)\n",
    "    plt.title('|Slice after reflection|')\n",
    "    plt.xlabel(\"y (voxels)\")\n",
    "    plt.ylabel(\"x (voxels)\")\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.imshow(torch.abs(exit_wave).cpu(),aspect=0.1)\n",
    "    plt.title('|Exit wave| (final slice)')\n",
    "    plt.xlabel(\"y (voxels)\")\n",
    "    plt.ylabel(\"x (voxels)\")\n",
    "    # pre_FT = torch.fft.fftshift(torch.fft.fft2(pre_EW))\n",
    "    # mid_FT = torch.fft.fftshift(torch.fft.fft2(midEW))\n",
    "\n",
    "    # plt.figure(figsize=[5,5])\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.imshow(torch.log(torch.abs((F1))+1e-20).cpu(),aspect=1,vmin=recon_FFT_vmin,vmax=recon_FFT_vmax)\n",
    "    plt.title(\"FT[exit wave]\")\n",
    "    plt.xlabel(\"uy (voxels)\")\n",
    "    plt.ylabel(\"uz (voxels)\")\n",
    "    \n",
    "    # plt.figure(figsize=[10,5])\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.imshow((torch.abs(sideslice.cpu())),aspect='auto')\n",
    "    plt.title(\"side-on view\")\n",
    "    plt.xlabel(\"z (voxels)\")\n",
    "    plt.ylabel(\"x (voxels)\")\n",
    "\n",
    "    # plt.subplot(2,3,5)\n",
    "    # plt.imshow(torch.log(torch.abs((F1))+1e-20).cpu(),aspect=1,vmin=recon_FFT_vmin,vmax=recon_FFT_vmax)\n",
    "    # plt.title(\"FT[exit wave]\")\n",
    "    # plt.subplot(1,3,3)\n",
    "    # plt.imshow(torch.log(torch.abs((GT[:,:,-5]**0.5))+1e-20).cpu(),aspect=1,vmin=recon_FFT_vmin,vmax=recon_FFT_vmax)\n",
    "    \n",
    "    print(\"exit wave norm\",torch.norm(torch.abs(F1)))\n",
    "    print(\"exit wave max\",torch.max(torch.abs(F1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095a46d0-a270-46ea-b979-c3c4e40412bb",
   "metadata": {},
   "source": [
    "## Assert that the exit wave simulation window size matches the data/detector window size.\n",
    "### not needed for simulated data, but useful for real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_size = (F1).size()\n",
    "\n",
    "print(\"size of GT  crop\",crop_window_size)\n",
    "print(\"size of EW\",F1_size)\n",
    "# print(\"difference\",(F1_size[0] - crop_window_size[0]),(F1_size[1] - crop_window_size[1]))\n",
    "# print(\"old EWCI\", EWCI)\n",
    "# print(\"new EWCI should be\",EWCI[0]+(F1_size[0] - crop_window_size[0])/2,EWCI[2]+(F1_size[1] - crop_window_size[1])/2)\n",
    "assert (F1_size[0] == crop_window_size[0]) & (F1_size[1] == crop_window_size[1]) , \"EWCI isnt the same\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38071855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.imshow((torch.abs((midslice)).detach().cpu()))\n",
    "# plt.title(\"beam footprint on substrate\")\n",
    "plt.figure()\n",
    "plt.plot(((torch.abs(midslice.cpu()))[:,int(full_sim_size[2]/2)]))\n",
    "\n",
    "plt.title(\"beam profile at midpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1392d5-c7e6-4280-bc0b-6acf7087a852",
   "metadata": {},
   "source": [
    "## Define beam footprint mask. This will be to aid with a real space constraint in the volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a7ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_footprint_radius_y_voxels = (1.9e-6/(voxel_size[1]*downscaling_factor_y))\n",
    "beam_footprint_radius_z_voxels = (1.9e-6*oversample_factor/np.sin(np.deg2rad(inc_angle_list[0])))/(slab_thickness*downscaling_factor_z)\n",
    "beam_footprint_ratio = beam_footprint_radius_z_voxels/beam_footprint_radius_y_voxels\n",
    "beam_footprint_buffer = 1\n",
    "beam_footprint_blur = 5\n",
    "beamfootprints = (torch.ones(1,xr.size(1),xr.size(2)))\n",
    "print(beamfootprints.size())\n",
    "for n1 in range(len(new_yposindex)):\n",
    "    \n",
    "    beamfootprints[:,(new_yposindex[n1][0]):(new_yposindex[n1][1]),\n",
    "                      (new_zposindex[n1][0]):(new_zposindex[n1][1])] += make_prop_mask(beamfootprints[0,int(new_yposindex[n1][0]):int(new_yposindex[n1][1]),int(new_zposindex[n1][0]):int(new_zposindex[n1][1])].rot90(1),(beam_footprint_radius_y_voxels+beam_footprint_buffer).cpu().numpy(),beam_footprint_blur,beam_footprint_ratio).rot90(-1)+1e-3\n",
    "\n",
    "\n",
    "    \n",
    "iii = 2\n",
    "thisxrtest = xr[0,int(new_yposindex[iii][0]+yzpad):int(new_yposindex[iii][1]+yzpad),\n",
    "                   int(new_zposindex[iii][0]+yzpad):int(new_zposindex[iii][1]+yzpad)]\n",
    "masktest1 = make_prop_mask(thisxrtest.rot90(1),(beam_footprint_radius_y_voxels+beam_footprint_buffer).cpu().numpy(),beam_footprint_blur,beam_footprint_ratio).rot90(-1)+1e-4\n",
    "# beamfootprints = beamfootprints.unsqueeze(-1)\n",
    "# print(thisxrtest.size())\n",
    "# print(masktest1.size())\n",
    "# print(midslice.size())\n",
    "plt.figure(figsize=[10,5])\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(masktest1.detach().cpu(),aspect=2)\n",
    "plt.title(\"single scan footprint mask\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(torch.abs(midslice).detach().cpu(),aspect=2/oversample_factor)\n",
    "plt.title(\"beam footprint on substrate\")\n",
    "plt.figure(figsize=[15,5])\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(beamfootprints[0,:,:].cpu(),aspect=0.9), plt.colorbar()\n",
    "plt.title(\"beam footprints with mask applied\")\n",
    "\n",
    "beam_footprints_binary = beamfootprints.clone()\n",
    "beam_footprints_binary[beam_footprints_binary<2] = 0\n",
    "beam_footprints_binary[beam_footprints_binary>=2] = 1\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(beam_footprints_binary[0,:,:].cpu(),aspect=0.9), plt.colorbar()\n",
    "plt.title(\"beam footprints binary mask\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185187f9-0bc2-4f7d-9310-e13459cdd3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_per_spoke_modulated_siemens_star(\n",
    "    width=512, height=512,\n",
    "    num_spokes=36,\n",
    "    r_inner=50, r_outer=200,\n",
    "    modulated_spokes=None  # dict: {index: (r_inner_alt, r_outer_alt)}\n",
    "):\n",
    "    if modulated_spokes is None:\n",
    "        modulated_spokes = {}\n",
    "\n",
    "    # Create coordinate grid\n",
    "    y, x = np.ogrid[:height, :width]\n",
    "    cx, cy = width // 2, height // 2\n",
    "    x = x - cx\n",
    "    y = y - cy\n",
    "\n",
    "    # Convert to polar\n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    theta = np.arctan2(y, x)\n",
    "    theta_norm = (theta + np.pi) / (2 * np.pi)\n",
    "\n",
    "    # Spoke indices\n",
    "    spoke_idx = (theta_norm * num_spokes).astype(int)\n",
    "\n",
    "    # Alternating spoke pattern\n",
    "    is_spoke = ((theta_norm * num_spokes) % 1) < 0.5\n",
    "\n",
    "    # Initialize radius maps with default values\n",
    "    r_outer_map = np.full_like(r, r_outer, dtype=float)\n",
    "    r_inner_map = np.full_like(r, r_inner, dtype=float)\n",
    "\n",
    "    # Apply custom values for each modulated spoke\n",
    "    for idx, (ri_alt, ro_alt) in modulated_spokes.items():\n",
    "        mask = spoke_idx == idx\n",
    "        r_outer_map[mask] = ro_alt\n",
    "        r_inner_map[mask] = ri_alt\n",
    "\n",
    "    # Mask for radius within bounds\n",
    "    radius_mask = (r >= r_inner_map) & (r <= r_outer_map)\n",
    "\n",
    "    # Final Siemens star\n",
    "    siemens_star = is_spoke & radius_mask\n",
    "\n",
    "    return torch.tensor(siemens_star.astype(np.float32)).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef4db1-fac1-4cff-97ed-9d87bc1d1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_GT_structure(width,height,bsx=1550,bsy=-170,downscaley = 1,downscalez = 1,height_voxels=2):\n",
    "    image_tensor = torch.zeros(1, 1, height, width)  # 1 channel (grayscale), 1 batch\n",
    "    for n1 in range(erclogo.shape[0]):\n",
    "    \n",
    "        patch_coords = (round((erclogo[n1,0])/(voxel_size[1]*downscaley).cpu().numpy()+bsx),\n",
    "                        round((erclogo[n1,1])/(slab_thickness*downscalez).cpu().numpy()-((min(erclogo[:,1])/(slab_thickness*downscalez).cpu().numpy()+bsy))),\n",
    "                        round((erclogo[n1,0]+erclogo[n1,2])/(voxel_size[1]*downscaley).cpu().numpy()+bsx),\n",
    "                        round((erclogo[n1,1]+erclogo[n1,3])/(slab_thickness*downscalez).cpu().numpy()-((min(erclogo[:,1])/(slab_thickness*downscalez).cpu().numpy()+bsy))))\n",
    "    \n",
    "        mask = torch.zeros(1, 1, height, width)  # Initialize with zeros\n",
    "        \n",
    "        mask[:, :, patch_coords[1]:patch_coords[3], patch_coords[0]:patch_coords[2]] = 1\n",
    "    \n",
    "        # Apply the mask to the image tensor to create a binary image\n",
    "        image_tensor = image_tensor + mask\n",
    "        image_tensor = torch.clamp(image_tensor,0,1)\n",
    "    image_tensor = image_tensor.squeeze().flip(0)*height_voxels\n",
    "    return image_tensor.unsqueeze(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b23c64-9614-4d74-9f3c-89e1c460d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create ground truth structure.\n",
    "# ground_truth_image = create_GT_structure(xr_z_size,xr_y_size,bsx=450,bsy=-50,downscaley = 10,downscalez = 1,height_voxels=1)\n",
    "# ground_truth_image = generate_fully_modulated_siemens_star(\n",
    "    # width=xr_z_size, height=xr_y_size,num_spokes=35,r_inner=15, r_outer=200,r_inner_alt=80, r_outer_alt=200,n_modulate=5)\n",
    "modulated = {\n",
    "    1: (60, 150),\n",
    "    4: (70, 160),\n",
    "    7: (80, 170),\n",
    "    10: (90, 180),\n",
    "    13: (100, 190),\n",
    "    16: (110, 200),\n",
    "    19: (120, 200),\n",
    "    22: (130, 200),\n",
    "    24: (140, 200),\n",
    "    # 25: (100, 200),\n",
    "    # 28: (110, 200),\n",
    "    # 31: (120, 200),\n",
    "    # 34: (130, 200),\n",
    "\n",
    "    \n",
    "    \n",
    "}\n",
    "ground_truth_image = generate_per_spoke_modulated_siemens_star(width=xr_z_size,\n",
    "                                                               height=xr_y_size,\n",
    "                                                               num_spokes=25,\n",
    "                                                               r_inner=15, \n",
    "                                                               r_outer=200,\n",
    "                                                               modulated_spokes=modulated)\n",
    "# ground_truth_image = generate_custom_modulated_siemens_star(\n",
    "#     width=xr_z_size, height=xr_y_size,num_spokes=35,r_inner=15, r_outer=200,r_inner_alt=80, r_outer_alt=150,modulated_spoke_indices=[1,4,8,13,19,26,34])\n",
    "ny, nx = ground_truth_image.squeeze().shape\n",
    "extent = [0, nx * slab_thickness.cpu()*1e6, 0, ny * voxel_size[1].cpu()*1e6]\n",
    "plt.imshow(ground_truth_image.squeeze().cpu(),extent=extent,aspect='auto'),plt.colorbar()\n",
    "plt.title(\"Ground Truth\")\n",
    "plt.ylabel(\"y (m)\")\n",
    "plt.xlabel(\"z (m)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3140e9c-c243-42e6-b41a-022ab345d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create simulated diffrac patterns:\n",
    "with torch.no_grad():\n",
    "    GTs = torch.zeros_like(GT)\n",
    "    this_GT_str = ground_truth_image\n",
    "    for iii in range(num_scans):\n",
    "            \n",
    "            print(\"creating sim data diffrac. patterns:\",(iii+1), \"/\", num_scans,end=\"\\r\")\n",
    "            this_xr = fill_3d_tensor(this_GT_str[0,int(new_yposindex[iii][0]+yzpad):int(new_yposindex[iii][1]+yzpad),\n",
    "                           int(new_zposindex[iii][0]+yzpad):int(new_zposindex[iii][1]+yzpad)],params_size[0],oversample_structure,oversample_factor)\n",
    "            sim_probe_in = combine_probe_modes(probes_param,0)\n",
    "            waveout,_ = multislice_3stage(\n",
    "                    this_xr,\n",
    "                    full_sim_size, params_size, voxel_size, slab_thickness,\n",
    "                    inc_angle_list[iii], slab_pad_pre, slab_pad_post, sim_probe_in,\n",
    "                    probe_buffer,1,shift_amount,substrate_layers,\n",
    "                    init_xr_substrateamt,top_buffer,0,subpixel_shifts_y[iii],subpixel_shifts_z[iii],hx_shift[int(scan_identifier_list[iii])],hz_shift[int(scan_identifier_list[iii])])\n",
    "                #crop exit wave\n",
    "            out1 = torch.abs(waveout[EWCI[0]:-EWCI[1],EWCI[2]:-EWCI[3]])#*mean_1d_perscan[:,:,iii]\n",
    "            \n",
    "            GTs[:,:,iii] = out1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c43e09-5f38-4310-a2a4-8f9a2dd40693",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # plt.imshow(this_xr[-2,:,:].cpu())\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(torch.log(GTs[:,:,4]).cpu()),plt.colorbar()\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.imshow(this_GT_str[0,int(new_yposindex[iii][0]+yzpad):int(new_yposindex[iii][1]+yzpad),\n",
    "                           int(new_zposindex[iii][0]+yzpad):int(new_zposindex[iii][1]+yzpad)].cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8476a5",
   "metadata": {},
   "source": [
    "## Run the Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45065a40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "psr = probes_param.size(0)/probes_param.size(1)\n",
    "wave_deletion_mask = 1\n",
    "# normal partial voxels, grads are not accumulated but optimsied after each scan.\n",
    "fig = plt.figure(figsize=[10,10])\n",
    "divergence_count = 0\n",
    "#start the loop\n",
    "for i in range(num_iters):\n",
    "\n",
    "    mstime1 = time.time()\n",
    "    scan_orders = (list(range(num_scans)))\n",
    "    random.shuffle(scan_orders)\n",
    "    scan_counter = 0\n",
    "    #zero grad \"storage\" tensors\n",
    "    probes_cumulative_grad = torch.zeros_like(probes_param)\n",
    "    spsz_cumulative = torch.zeros_like(subpixel_shifts_z)\n",
    "    spsy_cumulative = torch.zeros_like(subpixel_shifts_y)\n",
    "    hx_cumulative = torch.zeros_like(hx_shift)\n",
    "    hz_cumulative = torch.zeros_like(hz_shift)\n",
    "\n",
    "    xrg *= 0\n",
    "\n",
    "    for iii in scan_orders:\n",
    "        #zero optimizers\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_adam.zero_grad()\n",
    "        probe_optimizer.zero_grad()\n",
    "        prop_optim.zero_grad()\n",
    "        if optimize_scan_offsets ==  1 :\n",
    "            scan_positions_optim.zero_grad()\n",
    "        # if use_noise == 1:\n",
    "        #     noise_optim.zero_grad()\n",
    "        \n",
    "        resized_probe = combine_probe_modes(probes_param,iii)\n",
    "        if use_multiple_probe_modes == True:\n",
    "            probes_in_unshifted = (resized_probe)\n",
    "        else:\n",
    "            probes_in_unshifted = (resized_probe)\n",
    "     \n",
    "        probes_in_shifted = probes_in_unshifted\n",
    "        # Forward pass\n",
    "        this_xr = fill_3d_tensor((xr)[0,int(new_yposindex[iii][0]+yzpad):int(new_yposindex[iii][1]+yzpad),\n",
    "               int(new_zposindex[iii][0]+yzpad):int(new_zposindex[iii][1]+yzpad)],params_size[0],oversample_structure,oversample_factor)\n",
    "        \n",
    "\n",
    "        #actually do the multislice:\n",
    "        waveout,_ = multislice_3stage(\n",
    "            this_xr,\n",
    "            full_sim_size, params_size, voxel_size, slab_thickness,\n",
    "            inc_angle_list[iii], slab_pad_pre, slab_pad_post, probes_in_shifted,\n",
    "            probe_buffer,wave_deletion_mask,shift_amount,substrate_layers,\n",
    "            init_xr_substrateamt,top_buffer,0,subpixel_shifts_y[iii],subpixel_shifts_z[iii],hx_shift[int(scan_identifier_list[iii])],hz_shift[int(scan_identifier_list[iii])])\n",
    "        #crop exit wave\n",
    "        out1 = torch.abs(waveout[EWCI[0]:-EWCI[1],EWCI[2]:-EWCI[3]])\n",
    "        with torch.no_grad(): \n",
    "            out1.data[torch.isnan(out1.data)] = 0\n",
    "        #apply Total Variation Penalties / other regularizers\n",
    "        if i < tv_start:\n",
    "            tvx = 0\n",
    "            tvy = 0\n",
    "            tvz = 0\n",
    "            tvsy = 0\n",
    "            tvsz = 0\n",
    "#             voxel_weights = 0\n",
    "        else:\n",
    "\n",
    "            if use_per_scan_TV == True:\n",
    "                tvx = 0#torch.nansum(torch.abs(torch.diff(xr[:,int(new_yposindex[iii][0]+yzpad):int(new_yposindex[iii][1]+yzpad),\n",
    "               #int(new_zposindex[iii][0]+yzpad):int(new_zposindex[iii][1]+yzpad)],dim=0)**2))*tvx_alpha\n",
    "            else:\n",
    "                tvx = 0#torch.nanmean(torch.abs(torch.diff(xr,dim=0)**2))*tvx_alpha#torch.nansum(torch.abs(torch.diff(xr[:,dzy+yzpad:-(dzy+yzpad),dzz+yzpad:-(dzz+yzpad)],dim=0)**2))*tvx_alpha\n",
    "            if use_per_scan_TV == True:\n",
    "                tvy = torch.nansum(torch.abs(torch.diff(xr[0,int(new_yposindex[iii][0]+yzpad):int(new_yposindex[iii][1]+yzpad),\n",
    "                   int(new_zposindex[iii][0]+yzpad):int(new_zposindex[iii][1]+yzpad)],dim=1)**2))*tvy_alpha \n",
    "                tvz = torch.nansum(torch.abs(torch.diff(xr[0,int(new_yposindex[iii][0]+yzpad):int(new_yposindex[iii][1]+yzpad),\n",
    "                   int(new_zposindex[iii][0]+yzpad):int(new_zposindex[iii][1]+yzpad)],dim=2)**2))*tvz_alpha \n",
    "            else: \n",
    "                tvy = torch.nanmean(torch.abs(torch.diff(xr[0,:,:],n=1,dim=0)**2))**0.5*tvy_alpha \n",
    "                tvz = torch.nanmean(torch.abs(torch.diff(xr[0,:,:],n=1,dim=1)**2))**0.5*tvz_alpha \n",
    "        tv_total = (tvx+tvy+tvz)*tvt_alpha\n",
    "        \n",
    "        \n",
    "        this_GT = GTs[:,:,iii]#*detector_mask_crop\n",
    "        #normalise total flux of ecah scan perhaps ? \n",
    "        with torch.no_grad():\n",
    "            flux_ratio = 1\n",
    "        #calculate the loss \n",
    "        if use_noise == 1:\n",
    "            this_diff = (torch.abs((torch.abs(this_GT)) - (((out1)))))**2\n",
    "            loss = torch.nanmean(this_diff)+tv_total\n",
    "        else:\n",
    "            loss = torch.nanmean((torch.abs((torch.abs(this_GT)) - (((out1)))))**2)+tv_total\n",
    "\n",
    "        allocated_memory = torch.cuda.memory_allocated()\n",
    "        backtime1 = time.time()\n",
    "        \n",
    "        ### the all important backward function ###\n",
    "        loss.backward()\n",
    "        #after backward:\n",
    "\n",
    "        #optimize scan offsets if youre doing that\n",
    "        if optimize_scan_offsets ==  1 :\n",
    "            if i > 10:\n",
    "                spsz_cumulative += subpixel_shifts_z.grad\n",
    "                spsy_cumulative += subpixel_shifts_y.grad\n",
    "                hx_cumulative += hx_shift.grad\n",
    "                hz_cumulative += hz_shift.grad\n",
    "                \n",
    "        #start storing gradients of the recon structure into xrg\n",
    "        if do_gradient_accumulation == True:\n",
    "            with torch.no_grad():\n",
    "                this_xrg = xr.grad[:,int(new_yposindex[iii][0]+yzpad):int(new_yposindex[iii][1]+yzpad),\n",
    "                                   int(new_zposindex[iii][0]+yzpad):int(new_zposindex[iii][1]+yzpad)]\n",
    "                this_xrg[torch.isnan(this_xrg)] = 0\n",
    "\n",
    "                \n",
    "                xrg[:,int(new_yposindex[iii][0]+yzpad):int(new_yposindex[iii][1]+yzpad),\n",
    "                   int(new_zposindex[iii][0]+yzpad):int(new_zposindex[iii][1]+yzpad)] += this_xrg\n",
    "        else: \n",
    "            with torch.no_grad():\n",
    "                this_xrg = xr.grad[0,int(new_yposindex[iii][0]+yzpad):int(new_yposindex[iii][1]+yzpad),\n",
    "                                   int(new_zposindex[iii][0]+yzpad):int(new_zposindex[iii][1]+yzpad)]\n",
    "                optimizer.param_groups[0]['lr'] = (grads_target/(torch.mean(this_xrg)+torch.std(this_xrg)))\n",
    "            \n",
    "            if i< 500:\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                optimizer_adam.step()\n",
    "            xr.data = torch.clamp(xr.data,0,params_size[0])\n",
    "\n",
    "        \n",
    "        #accumulate grads for probe param and prop amt.\n",
    "        with torch.no_grad():\n",
    "            probes_cumulative_grad += probes_param.grad\n",
    "            probes_cumulative_grad[torch.isnan(probes_cumulative_grad)] = 0\n",
    "#             PO += probe_prop_amt.grad\n",
    "        # if use_noise == 1:\n",
    "        #     noise_optim.step()\n",
    "        #     #noise is modelled as a normal distribution, and so we clip it to within 3 std of mean.\n",
    "        #     noise_guess.data = torch.clamp(noise_guess.data,0,(noise_mean+3*noise_std))\n",
    "    \n",
    "\n",
    "        backtime2 = time.time()\n",
    "        scan_counter += 1\n",
    "        loss_tracker[i,iii] = loss.item()\n",
    "        print_progress_bar(scan_counter + 1, num_scans)\n",
    "        \n",
    "        \n",
    "        ### end loop over scans###\n",
    "    #reapply gradients and actually update the structure\n",
    "    if do_gradient_accumulation == True:\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_adam.zero_grad()\n",
    "        if using_n_scans_per_pixel == True:\n",
    "            xr.grad = xrg/beamfootprints #warning: cant also be in the previous bit of code... \n",
    "        else:        \n",
    "            xr.grad = xrg\n",
    "\n",
    "        if i< 500:\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            optimizer_adam.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            xr.data = torch.clamp(xr.data,0,params_size[0])#*beam_footprints_binary\n",
    "            xr.data[torch.isnan(xr.data)] = 0\n",
    "        # if i == 0:\n",
    "        #     optimizer.param_groups[0]['lr'] = 1e6\n",
    "            # if i == 4:\n",
    "            #     str = xr>torch.quantile((xr[xr>0]),0.8)\n",
    "            #     xr[str].data += 3\n",
    "            \n",
    "    subpixel_shifts_y.grad = spsy_cumulative\n",
    "    subpixel_shifts_z.grad = spsz_cumulative\n",
    "    hx_shift.grad = hx_cumulative \n",
    "    hz_shift.grad = hz_cumulative \n",
    "    # scan_positions_optim.step()\n",
    "    subpixel_shifts_z.data = torch.clamp(subpixel_shifts_z.data,-2e-7,2e-7)\n",
    "    subpixel_shifts_y.data = torch.clamp(subpixel_shifts_y.data,-2e-6,2e-6)\n",
    "    hx_shift.data = torch.clamp(hx_shift.data,-2e-6,2e-6)\n",
    "    hz_shift.data = torch.clamp(hz_shift.data,-2e-7,2e-7)\n",
    "    #transfer probe cumulative gra ot the actual tensor.\n",
    "    probes_param.grad = probes_cumulative_grad/num_scans\n",
    "    \n",
    "    \n",
    "    \n",
    "    #only update the probe after 'probestart'\n",
    "    if i > probestart:\n",
    "        with torch.no_grad():\n",
    "            if i < 8: #only have this high LR for the first few iterations.\n",
    "                probe_optimizer.param_groups[0]['lr'] = probe_grads_target/(torch.mean(torch.abs(probes_cumulative_grad/num_scans))+torch.std(probes_cumulative_grad/num_scans)) \n",
    "        # probe_optimizer.step()\n",
    "        probes_param.data[torch.isnan(probes_param)] = 0\n",
    "#         probes_param.data[torch.isnan(probes_param)] = probe_orig.data[torch.isnan(probes_param)]\n",
    "\n",
    "    with torch.no_grad():    \n",
    "\n",
    "        if probe_is_FFT == 1:\n",
    "                pass #probes_param.data = torch.fft.fftshift(torch.fft.fft2(torch.fft.ifft2(torch.fft.fftshift(probes_param.data))*make_prop_mask(orig_csaxs_probe,80,5,1)))\n",
    "        else:\n",
    "                for n3 in range((probes_param.size(2))):    \n",
    "                    probes_param[:,:,n3].data *= torch.clamp(make_prop_mask(probes_param[:,:,0].data,95,3,psr),1e-8,1)\n",
    "\n",
    "             \n",
    "    if i > divergence_count_start:            \n",
    "        if (np.mean(loss_tracker,1)[i-1]) < (np.mean(loss_tracker,1)[i]):\n",
    "            divergence_count += 1 \n",
    "            print(\"loss increasing, count:\",divergence_count)\n",
    "\n",
    "        if divergence_count > divergence_thr:\n",
    "            grads_target *= 0.5\n",
    "            probe_grads_target *= 0.5\n",
    "            optimizer.param_groups[0]['lr'] *= 0.5\n",
    "            optimizer_adam.param_groups[0]['lr'] *= 0.5\n",
    "            probe_optimizer.param_groups[0]['lr'] *= 0.5\n",
    "            \n",
    "            tvt_alpha *= 0.7\n",
    "            if using_rprop == 1:\n",
    "                optimizer.param_groups[0]['step_sizes'] = (optimizer.param_groups[0]['step_sizes'][0]*0.8,\n",
    "                                                           optimizer.param_groups[0]['step_sizes'][1])\n",
    "\n",
    "\n",
    "            print('loss increasing, reducing lr, tv')\n",
    "            divergence_count = 0\n",
    "\n",
    "\n",
    "    xr.data = torch.clamp(xr.data,0,params_size[0])\n",
    "\n",
    "    mstime2 = time.time()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Backpropagation\n",
    "    hz_shift_formatted = \" \".join(\"%2.2E\" % x.item() for x in hz_shift.data)\n",
    "    hx_shift_formatted = \" \".join(\"%2.2E\" % x.item() for x in hx_shift.data)\n",
    "    print()\n",
    "    print(\"=======\")\n",
    "    print(i+1, \"/\", num_iters, \"%2.5E\" % np.mean(loss_tracker[i]), \n",
    "          \"mem used:\", \n",
    "          allocated_memory // (1024 * 1024), \"MB\",\n",
    "          \"MS fwd time\", \"%2.2F\" % (mstime2-mstime1),\n",
    "          \"Bkwd time\", \"%2.2F\" % ((backtime2-backtime1)))\n",
    "    print(\"typical loss\", \"%2.2E\" %torch.mean(torch.abs(torch.abs(GT[:,:,iii])\n",
    "                                    - torch.abs(out1))**2),\n",
    "          \"typical tvx\", \"%2.2E\" % tvx,\n",
    "          \"typical tvy\", \"%2.2E\" % tvy,\n",
    "          \"typical tvz\", \"%2.2E\" % tvz,\n",
    "          \"typical tv_total\", \"%2.2E\" % tv_total,\n",
    "          \"calculated learning rate\", \"%2.2E\" % (optimizer.param_groups[0]['lr']),\n",
    "          \"calculated probe learning rate\", \"%2.2E\" % (probe_optimizer.param_groups[0]['lr'])\n",
    "          \n",
    "         )\n",
    "    print(\"=======\")\n",
    "    if i > 0:\n",
    "        ax.cla()\n",
    "        plt.close(fig)\n",
    "        plt.close()\n",
    "        fig = plt.figure(figsize=[10,10])\n",
    "    # iters_out = torch.cat((iters_out,xr[0,:,:].detach()),0)\n",
    "    \n",
    "    ax1 = fig.add_subplot(2,2,1)\n",
    "\n",
    "    if not ((dzz == 0) & (dzy == 0) & (yzpad == 0)):    \n",
    "        im1 = ax1.imshow(torch.sum(xr[:,(dzy+yzpad):-(dzy+yzpad),(dzz+yzpad):-(dzz+yzpad)].detach().cpu(),dim=0), interpolation='none', aspect=2.5)\n",
    "    else:\n",
    "        im1 = ax1.imshow((xr[0,:,:].detach().cpu()), interpolation='none', aspect=1)\n",
    "        \n",
    "    fig.colorbar(im1, ax=ax1)  # Add colorbar to the first subplot\n",
    "    \n",
    "    ax2 = fig.add_subplot(2,2,2)\n",
    "    if use_multiple_probe_modes == True:\n",
    "        im2 = ax2.imshow(torch.abs(combine_probe_modes(probes_param,iii)).detach().cpu(), vmin=0, vmax=probe_vmax, interpolation='none', aspect=1/psr)\n",
    "    else:\n",
    "        im2 = ax2.imshow(torch.abs(combine_probe_modes(probes_param,iii)).detach().cpu(), vmin=0, vmax=probe_vmax, interpolation='none', aspect=1/psr)\n",
    "    \n",
    "    ax3 = fig.add_subplot(2,2,3)\n",
    "    ax3.imshow(torch.log((torch.abs(out1)*flux_ratio)+1e-9).detach().cpu(), vmin=recon_FFT_vmin, vmax=recon_FFT_vmax, interpolation='None')\n",
    "    \n",
    "    ax4 = fig.add_subplot(2,2,4)\n",
    "    ax4.imshow(torch.log(torch.abs(this_GT)+1e-9).detach().cpu(), vmin=recon_FFT_vmin, vmax=recon_FFT_vmax, interpolation='None')\n",
    "    display(fig)\n",
    "    \n",
    "total_sim_end_time = time.time()\n",
    "print()\n",
    "print(\"finished\")\n",
    "\n",
    "print(\"total time for\",num_iters,\"iters:\", \"%2.2f\" % ((total_sim_end_time-total_sim_start_time)/60),\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2becde-7aeb-4995-b313-ff2bdb64e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    plt.figure(figsize=[15,5])\n",
    "    plt.subplot(1,2,1)\n",
    "    \n",
    "    \n",
    "    ny, nx = xr.squeeze().shape\n",
    "    extent = [0, nx * slab_thickness.cpu()*1e6, 0, ny * voxel_size[1].cpu()*1e6]\n",
    "    plt.imshow((xr*voxel_size[0]*1e9).squeeze().cpu(),extent=extent,aspect='auto')\n",
    "    cbar1 = plt.colorbar()\n",
    "    cbar1.set_label(\"height (nm)\")\n",
    "    plt.title(\"reconstruction\")\n",
    "    plt.ylabel(\"y (m)\")\n",
    "    plt.xlabel(\"z (m)\")\n",
    "\n",
    "\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow((ground_truth_image*voxel_size[0]*1e9).squeeze().cpu(),extent=extent,aspect='auto')\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.ylabel(\"y (m)\")\n",
    "    plt.xlabel(\"z (m)\")\n",
    "\n",
    "    \n",
    "    cbar2 = plt.colorbar()\n",
    "    cbar2.set_label(\"height (nm)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f9329-df59-49c4-beee-31dbae185cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=[10,5])\n",
    "\n",
    "lossmeans = np.mean(loss_tracker+1e-20,1)\n",
    "losserrs = np.std(loss_tracker+1e-20,1)\n",
    "plt.errorbar(np.arange(0,num_iters),lossmeans,losserrs)\n",
    "plt.plot((loss_tracker),alpha=0.1)\n",
    "plt.xlim([0,(i+5)])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"n iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc408cfb-49f5-4eb2-b877-641e0b0ecc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_filepath = '/your_output_directory/' \n",
    "save_filename = 'demo_script_output'\n",
    "today_date = datetime.today().strftime('%d-%m-%Y')\n",
    "full_filename = f\"{save_filepath}{save_filename}_{mean_radius*40}_nm_{today_date}.pt\"\n",
    "print(\"full filename\",full_filename)\n",
    "# Example metadata\n",
    "#blob_image,blob_heights,blob_x,blob_y,blob_rad,blob_width\n",
    "metadata = {\n",
    "    \"slab_thickness\": slab_thickness,\n",
    "    \"simulation_size\": full_sim_size,\n",
    "    \"voxel_size\": voxel_size,\n",
    "    \"probes\": probes_param,\n",
    "    \"oversample_factor\": oversample_factor,\n",
    "    \"num_inc_angles\": len(np.unique(inc_angle_list)),\n",
    "    \"inc_angles\": np.unique(inc_angle_list),\n",
    "    \"loss_function\": loss_tracker,\n",
    "\n",
    "    \"GT\": blob_tensor.detach(),\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "# Save tensor and metadata\n",
    "torch.save({\"recon\": xr.detach(), \"metadata\": metadata}, full_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028d42d8-1c7c-4fbe-b7a5-cb7e9ad8ea1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
