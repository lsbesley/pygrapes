{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5376112b",
   "metadata": {},
   "source": [
    "# PyGRAPES Simulation script\n",
    "\n",
    "## with default settings, this requires a GPU and uses approximately 5GB of VRAM. \n",
    "#### The simulation reconstructs a Au Siemens Star with height of 5 nm from simulated data at a wavelength of 6.02 keV and incidence angle of 0.7 degrees. \n",
    "#### running the notebook on CPU is in principle possible, but has not been tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78065cba-129c-435c-80a0-8f233447d7f3",
   "metadata": {},
   "source": [
    "### import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb814f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "# import scipy.io\n",
    "import h5py\n",
    "import matplotlib.patches as patches\n",
    "import sys\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import gc\n",
    "import torchvision\n",
    "from datetime import datetime\n",
    "from skimage.draw import disk, ellipse\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from IPython.display import display, clear_output\n",
    "from torchvision.transforms import v2\n",
    "import os\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db041b73-0224-4858-a698-4c7c7d4f6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygrapes_testbuild as pg "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173e2581-9ce0-46e5-a8c1-83e4376e755f",
   "metadata": {},
   "source": [
    "## Check CUDA is available and set default device.\n",
    "\n",
    "### in principle, the code should be able to run without a CUDA device, but this has not been tested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac3cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cuda device count:\",torch.cuda.device_count())\n",
    "print(\"cuda available:\",torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device('cuda:0')\n",
    "    torch.cuda.set_device('cuda:0')\n",
    "    print(\"setting default device to cuda\")\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "\n",
    "    for i in range(num_gpus):\n",
    "        # Get device properties\n",
    "        # device = torch.device(f'cuda:{i}')\n",
    "        properties = torch.cuda.get_device_properties(torch.device(f'cuda:{i}'))\n",
    "\n",
    "        # Print the total memory on the current GPU\n",
    "        print(f\"GPU {i}: {properties.name}, Total Memory: {properties.total_memory / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(\"current CUDA device is\", current_device)\n",
    "else: \n",
    "    print(\"cuda is not available. default device is CPU. Not tested\")\n",
    "\n",
    "\n",
    "def gpu_memcheck():\n",
    "    allocated_memory = torch.cuda.memory_allocated()\n",
    "    print(\"Currently allocated memory:\", allocated_memory // (1024 * 1024), \"MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f730db05-2a6b-4a22-b401-0a56a9c207e5",
   "metadata": {},
   "source": [
    "# Input Settings \n",
    "\n",
    "### The following 3 cells are where reconstruction settings are defined, such as simulation size, resolution, wavelength, and many others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821302ca-aa7c-4bc6-bf4b-b305f3d9185e",
   "metadata": {},
   "source": [
    "## (1/3)  Define Initial volume size and detector window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd5aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size = torch.tensor((5e-9,40e-9)) # (x,y) (normal to surface, perpendicular to x-ray propagation direction)\n",
    "slab_thickness = torch.tensor(500e-9) #z-direction resolution, parallel to x-ray propagation direction (thickness of 1 slice in multislice)\n",
    "full_sim_size = [1300,250,750] #a tuple specifying x,y,z size of the full volume.\n",
    "params_size = [10,full_sim_size[1],full_sim_size[2]] # a tuple specifying x,y,z size of optimizable structure (default y, and z are the same as full_sim_size).\n",
    "crop_window_size = [400,180] #[vertical pixels, horizontal pixels] equivalent to the window size of the detector used in in conventional ptychography (\"asize\" in ptychoshelves, for example).\n",
    "print(\"Voxel size, x:\", (voxel_size[0]*1e9).item(), \"nm, y:\",(voxel_size[1]*1e9).item(), \"nm\")\n",
    "print(\"Slab thickness:\", (slab_thickness*1e9).item(),\"nm\")\n",
    "\n",
    "\n",
    "probe_buffer = 0 #not used, but leave as 0\n",
    "shift_amount = 0 #not used, but leave as 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499040cf-7fbb-419d-9c23-9c004a3f9478",
   "metadata": {},
   "source": [
    "## (2/3) Define Experimental Wavelength, and define any refractive indices to be used in the reconstruction.\n",
    "\n",
    "##### the code refers to Audelta and Aubeta but these can be changed for other materials if the variable name is kept the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db6625f-acf9-42fd-8171-566b162e1199",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_val = torch.tensor(1.99983862803066e-10) #simulation Wavelength. Default  = 6.02 keV (commonly used at cSAXS, PSI)\n",
    "Audelta = torch.tensor(7.99106419e-05) #Since this simulation is only Au, we are just defining Au delta and beta for this energy.\n",
    "Aubeta = torch.tensor(1.24435501e-05) #Since this simulation is only Au, we are just defining Au delta and beta for this energy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea0f51-9880-4630-a76f-e6061e27eacb",
   "metadata": {},
   "source": [
    "## (3/3) Define Reconstruction specific Parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21bdd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization settings.\n",
    "using_n_scans_per_pixel = True #leave as true\n",
    "do_gradient_accumulation = True #whether structure is optimized after each scan (false), or after all scans are calculated (True) . Best left as true.\n",
    "load_previous = False #if loading a previously saved/optimised \n",
    "use_per_scan_TV = False #True means TV is calculated just for scan region rather than entire volume. best to leave as false.\n",
    "use_multiple_probe_modes = True #true probe mode modelling is not  implemented, but leave as true regardless.\n",
    "use_noise = True #best left as true, if noise is not needed, you can set noise to zero and noise LR to zero. False disables noise modelling entirely.\n",
    "optimize_scan_offsets = True #whether subpixel shifts and scan positions are optimized. Can leave as true, and set LR to zero.\n",
    "oversample_structure = True #whether to apply oversampling, more z slices than are used in the simulation. Leave as true, and set to 1, to not use oversampling.\n",
    "oversample_factor = 1 #leave as 1 to effectively turn oversampling off.\n",
    "\n",
    "# set learning rates and initial guesses.\n",
    "init_xr_scaling_factor = 0.02 #the magnitude (in voxels) of random fluctuatoin of your initial guess.\n",
    "init_xr_substrateamt = 0.00 #provide an offset of all initial values of initial guess.\n",
    "init_xr_learning_rate = 1e5 #initial learning rate seems high, but 1e5 has been tested to work reasonably well. \n",
    "grads_target = 0.1 #not used, leave at 0.1\n",
    "scan_positions_LR_fine = 1e-15 #per scan position optimization\n",
    "scan_positions_LR_coarse = 5e-15#position optimization of an entire set of scans. useful for coarse motor translations in stitch scans.\n",
    "probe_prop_LR = 1e-4 #not used at the moment.\n",
    "noise_std = 0 #noise init guess follows a gaussian dist, this provides Standard dev.\n",
    "noise_mean = 0 #noise init guess follows a gaussian dist, this provides mean.\n",
    "probe_grads_target = 1.0e-8 #rather than a learning rate, the probe has an average value of gradients, so that optimization is on average around the magnitude of this parameter\n",
    "\n",
    "#total variation regularization\n",
    "tvx_strength = 1 #to change the relative intensity of total variation in X direction. Not used in demo script.\n",
    "tvy_strength = 1 #to change the relative intensity of total variation in Y direction. Best left at 1 initially.\n",
    "tvz_strength = 1 #to change the relative intensity of total variation in Z direction. Best left at 1 initially.\n",
    "total_TV_strength = 1e-3 #total contributoin of ALL total variation penalty.\n",
    "\n",
    "#additional simulation settings.\n",
    "substrate_layers = 200 #number of layers from the bottom upwards of substrate. This shuold be enough to fully reflect/absorb the incoming beam.\n",
    "probe_substrate_buffer = 2 #extra spacing between probe and substrate.\n",
    "top_buffer = 0 #add padding in the final multislice component if the beam reflects too early or too steeply.\n",
    "pre_prop_dist_multiplier = 1.5 #add extra propagation distance before the beam encounters the structure.\n",
    "post_prop_dist_multiplier = 1 #add extra propagation distance after the beam encounters the structure.\n",
    "test_inc_angle = 0.7 # the incidence angle to test out these settings.\n",
    "slab_pad_pre = 0 #add extra slices, not used, but necessary atm for code to run.\n",
    "slab_pad_post = 0 #add extra slices, not used , but necessary atm for code to run.\n",
    "\n",
    "# hyperparamters\n",
    "num_iters = 50 #number of iteratoins to run for.\n",
    "probestart = 2 #iteration number at which the probe will begin optimising.\n",
    "tv_start = 2 #iteration number at which TV penalty will begin to apply.\n",
    "patience = 5 #number of iterations to wait for reducing LR if loss function is increasing.\n",
    "divergence_count_start = 5 #when LR scheduling begins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485a238-5cd0-46d6-aeb7-50d1d5e7ac4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b67f6-669d-427c-8c7a-ef10583aa22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb258fb-8cad-46c9-aadb-d1d8379094d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_memcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ceff4a-3022-4f60-9dff-408d0b03ff35",
   "metadata": {},
   "source": [
    "## Load scan positions, define ROI of scans, and specify incidence angle:\n",
    "### An incidence angle must be defined for each subscan, even if they are the same.\n",
    "### This simulation script comes with a premade position and scan list (demo_pz_values.npy,demo_px_values.npy). You can modify it yourself, or load your own one in as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b72991-2369-4b08-9138-573717fb4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_angle_list,scan_identifier_list,num_scans,ROI_inds_sub,corrected_ROI_inds,ROI_inds,cvals,all_px_values,all_pz_values,full_scan_identifier_list = pg.load_scan_positions()\n",
    "pg.plot_scan_points(cvals,full_scan_identifier_list,all_px_values,all_pz_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533e5909-d824-49a0-9bf8-7ca68c9a8347",
   "metadata": {},
   "source": [
    "## Convert scan positions into voxel positions. \n",
    "### This includes discretization to the nearest voxel. Discretization errors are compensated in the simulation through probe shifts, which are also calculated. \n",
    "#### Scan/probe positions are optimized during reconstruction according to their learning rate. Set learning rate to 0 to disable this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d09c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_scans = len(ROI_inds[0])\n",
    "print(\"num scans in this sim\",num_scans)\n",
    "\n",
    "scan_size_y = params_size[1]\n",
    "scan_size_z = params_size[2]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "px_voxels = (all_px_values[ROI_inds]*1e-6) / voxel_size[1].cpu().numpy()\n",
    "pz_voxels = (all_pz_values[ROI_inds]*1e-6) / slab_thickness.cpu().numpy()\n",
    "px_voxels = px_voxels.reshape(-1,1) \n",
    "pz_voxels = pz_voxels.reshape(-1,1) \n",
    "\n",
    "if np.min(px_voxels) < 0:\n",
    "    px_voxels += np.round(abs(np.min(px_voxels))+scan_size_y/2)\n",
    "\n",
    "elif np.min(px_voxels) >= 0:\n",
    "    px_voxels -= np.round(abs(np.min(px_voxels))-scan_size_y/2)\n",
    "    \n",
    "if np.min(pz_voxels) < 0:\n",
    "    pz_voxels += np.round(abs(np.min(pz_voxels))+scan_size_z/2)\n",
    "elif np.min(pz_voxels) >= 0:\n",
    "    pz_voxels -= np.round(abs(np.min(pz_voxels))-scan_size_z/2)\n",
    "\n",
    "#caluclate the subpixelshifts\n",
    "subpixel_shifts_z =  -torch.tensor((np.round(pz_voxels,decimals=0) - pz_voxels))\n",
    "subpixel_shifts_y =  torch.tensor((np.round(px_voxels,decimals=0) - px_voxels))\n",
    "\n",
    "\n",
    "#now create zposindex and yposindex.\n",
    "zposindex = []\n",
    "for i in range(num_scans):\n",
    "    zposindex.append((int(np.round(pz_voxels[i]-scan_size_z/2)+1),int(np.round(pz_voxels[i]+scan_size_z/2+1)+1)))\n",
    "yposindex = []\n",
    "for i in range(num_scans):\n",
    "    yposindex.append((int(np.round(px_voxels[i]-scan_size_y/2)+1),int(np.round(px_voxels[i]+scan_size_y/2+1)+1)))\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot((subpixel_shifts_z).cpu())\n",
    "plt.title(\"subpixel shifts Z\")\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot((subpixel_shifts_y).cpu())\n",
    "plt.title(\"subpixel shifts Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b13dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_sim_size_zdir = max(max(zposindex))\n",
    "full_sim_size_ydir = max(max(yposindex))\n",
    "\n",
    "xr_z_size = int(full_sim_size_zdir/1)\n",
    "print(\"size of all sims [y,z],\",full_sim_size_ydir,full_sim_size_zdir)\n",
    "downscaling_factor_z = (full_sim_size_zdir/xr_z_size)\n",
    "print(\"downscaling factor z (number of slices 1 z voxel represents):\" ,downscaling_factor_z)\n",
    "#so here we use this to convert the z indices\n",
    "z_indices_downscaled = zposindex\n",
    "new_zposindex = [(int(x / downscaling_factor_z), int(y / downscaling_factor_z)) for x, y in zposindex]\n",
    "# print(new_zposindex)\n",
    "\n",
    "xr_y_size = int(full_sim_size_ydir/1)\n",
    "# print(\"size of all sims [y,z],\",full_sim_size_ydir,full_sim_size_zdir)\n",
    "downscaling_factor_y = (full_sim_size_ydir/xr_y_size)\n",
    "print(\"downscaling factor y (number of slices 1 y voxel represents):\" ,downscaling_factor_y)\n",
    "#so here we use this to convert the z indices\n",
    "y_indices_downscaled = yposindex\n",
    "new_yposindex = [(int(x / downscaling_factor_y), int(y / downscaling_factor_y)) for x, y in yposindex]\n",
    "# print(new_yposindex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb50424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ea8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tilted plane correction has not been fully implemented, but was shown not to make a significant difference in testing. For now set to false :\n",
    "do_tilted_plane_corr = False\n",
    "num_scans1 = num_scans\n",
    "plt.figure(figsize=[10,10])\n",
    "GT = torch.zeros((crop_window_size[0],crop_window_size[1],num_scans))\n",
    "\n",
    "if do_tilted_plane_corr == 0:\n",
    "\n",
    "    mask = torch.ones_like(GT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d1f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign GT\n",
    "\n",
    "GT_out_pack = GT\n",
    "print(\"Size of GT exit waves:\",GT_out_pack.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d3a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear cache\n",
    "torch.cuda.empty_cache()\n",
    "#get memory\n",
    "gpu_memcheck()\n",
    "print(\"max memory allocated:\",\"%2.2E\" % (torch.cuda.max_memory_allocated()/(1024**3)), \"GiB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6624d2cf-0fcf-4465-884f-f600332ccf39",
   "metadata": {},
   "source": [
    "# Generate Model Probe (Defocused Fresnel Zone Plate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc084399-09f5-4793-aac8-d9714b640a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "new_flux = 4.0e-8\n",
    "probe_vmax = 8e-4\n",
    "probe_aspr = voxel_size[0]/voxel_size[1]\n",
    "recon_FFT_vmin = -5\n",
    "recon_FFT_vmax = 0\n",
    "n_probe_modes = int(np.max(scan_identifier_list) + 1)\n",
    "\n",
    "\n",
    "orig_csaxs_probe, model_probes = pg.generate_model_probe(\n",
    "    lambda_val=lambda_val,\n",
    "    voxel_size=voxel_size,\n",
    "    crop_window_size=crop_window_size,\n",
    "    scan_identifier_list=scan_identifier_list\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=[10,5])\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(torch.abs(model_probes[:,:,0]).cpu(),aspect=probe_aspr,vmin=0,vmax=probe_vmax), plt.colorbar()\n",
    "plt.title(\"input probe for sim\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "this_exit_wave_crop = v2.CenterCrop(size=(crop_window_size))(torch.abs(torch.fft.fftshift(torch.fft.fft2((model_probes[:,:,0]))))+1e-20)\n",
    "plt.imshow(torch.log(this_exit_wave_crop).cpu(),aspect=1)\n",
    "plt.title(\"FFT of input probe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7529d-2ebb-457f-a88f-568be98b964e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5936bd80",
   "metadata": {},
   "source": [
    "# This cell sets pytorch relevant initial parameters for the optimisaiton, and defines parameter tensors, optimizers and learning rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b8f429-bc31-451c-a65e-26b7a1487b8b",
   "metadata": {},
   "source": [
    "# this cell defines parameters and optimizers based on previously given input settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29612b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"full area covered by optimizable volume:\", \"%5.5E\" % (slab_thickness*full_sim_size[2]*1e6), \"um\" )\n",
    "yzaspr = (slab_thickness*downscaling_factor_z)/(voxel_size[1]*downscaling_factor_y)\n",
    "volsizeratio = xr_z_size/xr_y_size\n",
    "xy_voxel_size_ratio = voxel_size[0]/voxel_size[1]\n",
    "\n",
    "xr_x_size = 1 #leave as 1\n",
    "viewing_slice = 5 #not used\n",
    "yzpad = 0 #extra pad. This is from legacy code, but is solved by applying beam footprint masks elsewhere in code. Best left to zero.\n",
    "\n",
    "\n",
    "if using_n_scans_per_pixel == True and do_gradient_accumulation == False:\n",
    "    print(\"cannot have n_scans_per_pixel div if gradient accumulation is not used, setting ot true\")\n",
    "    do_gradient_accumulation == True\n",
    "\n",
    "if use_multiple_probe_modes == True:\n",
    "    print(\"using multiple probe modes\")\n",
    "\n",
    "    probe_in = model_probes.clone()\n",
    "\n",
    "else:\n",
    "    print(\"not using multiple probe modes\")\n",
    "\n",
    "    \n",
    "probe_prop_amt = torch.nn.Parameter(torch.tensor(1e-5))\n",
    "\n",
    "\n",
    "if load_previous:\n",
    "    probes_presave = torch.load('/home/lubs/pytorchnotebooks/Au_realdatatensor_probes_050608_conv_27-11-2024.pt')\n",
    "    # probe_in = torch.nn.Parameter(probes_presave)\n",
    "    probes_param = torch.nn.Parameter(probes_presave)\n",
    "else:\n",
    "    probes_param = torch.nn.Parameter(probe_in)\n",
    "\n",
    "\n",
    "\n",
    "print(\"final param size for this sim:\", xr_x_size,xr_y_size+yzpad*2,xr_z_size+yzpad*2)\n",
    "\n",
    "\n",
    "if optimize_scan_offsets == True:\n",
    "    subpixel_shifts_z = torch.nn.Parameter(-((torch.tensor((np.round(pz_voxels,decimals=0) - pz_voxels))*voxel_size[0])).clone())\n",
    "    subpixel_shifts_y = torch.nn.Parameter((torch.tensor((np.round(px_voxels,decimals=0) - px_voxels))*voxel_size[1]).clone())\n",
    "    hx_shift = torch.nn.Parameter(torch.rand(n_probe_modes)*1e-13)\n",
    "    hz_shift = torch.nn.Parameter(torch.rand(n_probe_modes)*1e-13)\n",
    "    scan_positions_optim = torch.optim.SGD([{'params': [subpixel_shifts_z,subpixel_shifts_y], 'lr': scan_positions_LR_fine},{'params': [hx_shift], 'lr': scan_positions_LR_coarse},{'params': [hz_shift], 'lr': scan_positions_LR_coarse}])\n",
    "    print(\"position optimization on\")\n",
    "\n",
    "if oversample_structure == True:\n",
    "    \n",
    "    xr = torch.nn.Parameter(torch.rand(1,xr_y_size,xr_z_size*oversample_factor)*init_xr_scaling_factor+init_xr_substrateamt)#torch.nn.Parameter((create_iso_random_initguess(xr_x_size,xr_y_size+yzpad*2,(xr_z_size+yzpad*2)*oversample_factor,(yzaspr))*init_xr_scaling_factor+init_xr_substrateamt))\n",
    "else:\n",
    "    oversample_factor = 1\n",
    "    xr = torch.nn.Parameter((create_iso_random_initguess(xr_x_size,xr_y_size+yzpad*2,xr_z_size+yzpad*2,(yzaspr))*init_xr_scaling_factor+init_xr_substrateamt))\n",
    "\n",
    "\n",
    "\n",
    "n_scans_per_pixel = (torch.ones_like(xr))\n",
    "#if youre using it or not:\n",
    "\n",
    "for n1 in range(len(new_yposindex)):\n",
    "    n_scans_per_pixel[:,(new_yposindex[n1][0]+yzpad):(new_yposindex[n1][1]+yzpad),\n",
    "                      (new_zposindex[n1][0]+yzpad):(new_zposindex[n1][1]+yzpad)] += 1 \n",
    "\n",
    "plt.imshow(n_scans_per_pixel[0,:,:].cpu()), plt.colorbar()\n",
    "\n",
    "if using_n_scans_per_pixel:\n",
    "    print(\"using n scans per pixel\")\n",
    "else:\n",
    "    print(\"not using n scans per pixel\")\n",
    "\n",
    "\n",
    "#model noise. not needed im simulated data. And so we set noise_guess to zero.\n",
    "\n",
    "noise_guess = torch.nn.Parameter(torch.clamp(torch.normal(torch.ones(crop_window_size[0],crop_window_size[1],num_scans)*noise_mean,torch.ones(crop_window_size[0],crop_window_size[1],num_scans)*noise_std),min=0))\n",
    "\n",
    "# Create an optimizer for the parameter xr #good lr is 2e-3!!\n",
    "#normal optim\n",
    "#are you doing gradient accumulation?\n",
    "if do_gradient_accumulation == True:\n",
    "    print('using gradient accumulation')\n",
    "else:\n",
    "    print('not using gradient accumulation')\n",
    "\n",
    "if use_per_scan_TV == True:\n",
    "    print('TV is calculated per scan area')\n",
    "else:\n",
    "    print('TV is calculated over entire volume')\n",
    "\n",
    "\n",
    "if use_noise == 1:\n",
    "    print('using noise addition')\n",
    "else:\n",
    "    print('not using noise addition')\n",
    "\n",
    "#### Are you using rprop or Adam ?\n",
    "\n",
    "\n",
    "if do_gradient_accumulation == 0:\n",
    "    optimizer = torch.optim.RAdam([{'params': [xr], 'lr': init_xr_learning_rate,'weight_decay':0}])      \n",
    "else:\n",
    "    optimizer = torch.optim.SGD([{'params': [xr], 'lr': init_xr_learning_rate,'weight_decay':0}])      \n",
    "    optimizer_adam = torch.optim.Adam([{'params': [xr], 'lr': 8e-3,'weight_decay':0}])\n",
    "probe_params = [ {'params': [probes_param], 'lr': 5e-2, 'weight_decay': 1e-20}]\n",
    "\n",
    "#noise optim is set to zero as it is not used in simulated data.\n",
    "noise_optim = torch.optim.RAdam([{'params': [noise_guess], 'lr': 0}])  \n",
    "\n",
    "probe_optimizer = torch.optim.SGD(probe_params)\n",
    "#scheduler for probe\n",
    "probe_LR_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(probe_optimizer, mode='min', \n",
    "                    factor=0.5, patience=4, threshold=0.0001, threshold_mode='rel',\n",
    "                    cooldown=0, min_lr=0, eps=1e-07)\n",
    "\n",
    "prop_optim = torch.optim.RAdam([{'params': [probe_prop_amt], 'lr': probe_prop_LR}]) #not used at the moment, but if probe propagation distance is to be optimized.\n",
    "\n",
    "loss_tracker = np.zeros((num_iters,num_scans))\n",
    "total_sim_start_time = time.time()\n",
    "iters_out = torch.tensor([])\n",
    "dzz = 0\n",
    "dzy = 0\n",
    "tvx_alpha =  tvx_strength*(xr_x_size*slab_thickness*downscaling_factor_z)/(params_size[0]*voxel_size[0]) #weight for TV in x direction\n",
    "print(\"tvx alpha\",tvx_alpha)\n",
    "tvy_alpha = tvy_strength#weight for TV in y direction\n",
    "print(\"tvy alpha\",tvy_alpha)\n",
    "tvz_alpha = tvz_strength #weight for TV in z direction\n",
    "tvt_alpha = total_TV_strength #total weight for all TV penalties  #if parial voxels, 1e-7 is typical, multiply by 1e6 or so if using complex\n",
    "\n",
    "\n",
    "divergence_thr = 2\n",
    "xrg = torch.zeros_like(xr)\n",
    "# PFM = torch.zeros_like(probefluxmult)\n",
    "# orig_probe_max = torch.max(probe_amp)\n",
    "print(\"patience (number of iters before reducing LR):\",(divergence_thr+1))\n",
    "postresizeprobemask_rad = 95\n",
    "psr = probes_param.size(0)/probes_param.size(1)\n",
    "wave_deletion_mask = 1\n",
    "divergence_count = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a683d96-eaeb-41a4-ba70-6e71255d9beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if oversample_structure:\n",
    "    new_zposindex = [(int(x * oversample_factor), int(y * oversample_factor)) for x, y in zposindex]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c0863",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.cuda.empty_cache()\n",
    "optimizer.zero_grad()\n",
    "probe_optimizer.zero_grad()\n",
    "prop_optim.zero_grad()\n",
    "gc.collect()\n",
    "# if use_noise == 1:\n",
    "    # noise_optim.zero_grad()\n",
    "gpu_memcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6dcd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EWCI = [528,528,1,1] #EWCI = Exit Wave Crop Indices. Crop the exit wave of the simulation to match the size of the data. Useful when working with real experimental data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790f5570-69fa-4827-9e31-6d9f9af14290",
   "metadata": {},
   "source": [
    "## Run a quick multislice forward simulation for diagnostic purposes.\n",
    "\n",
    "### Here you can check that the beam comes in, reflects, and exits, all within the space of the volume you defined.\n",
    "### this is a good point to check your simulation settings are okay, or if you need to go back and modify something, without having to run the entire reconstruction. It should only take a few seconds on a GPU\n",
    "#### The simulation follows this same code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de704636",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iii = 25\n",
    "with torch.no_grad():\n",
    "    \n",
    "    teststrin =  torch.zeros(params_size)\n",
    "        \n",
    "    probein = pg.combine_probe_modes(probes_param,0,scan_identifier_list) \n",
    "    probesize = probein.size()\n",
    "    pre_EW,pre_post_amt,probe_insertion_Y = pg.MSForward_GI_SS_novol_partialvoxel_pre(\n",
    "                        torch.zeros(params_size),lambda_val,\n",
    "                        full_sim_size, params_size, voxel_size, slab_thickness,\n",
    "                        test_inc_angle, slab_pad_pre, slab_pad_post, probein,\n",
    "                        probe_buffer,probe_substrate_buffer,1,0,substrate_layers,init_xr_substrateamt,0,0,0,0,0,Audelta,Aubeta)\n",
    "    midEW,midslice,sideslice = pg.MSForward_GI_SS_novol_partialvoxel_mid(teststrin,lambda_val,pre_EW,\n",
    "                   full_sim_size,params_size,voxel_size,slab_thickness,test_inc_angle,(substrate_layers),Audelta,Aubeta)\n",
    "\n",
    "    exit_wave = pg.MSForward_GI_SS_novol_partialvoxel_post(xr,lambda_val,midEW,\n",
    "                    full_sim_size,params_size,voxel_size,slab_thickness,test_inc_angle,(substrate_layers),pre_post_amt,post_prop_dist_multiplier,probe_insertion_Y,probesize,init_xr_substrateamt,Audelta,Aubeta)\n",
    "\n",
    "    F1 = torch.abs(torch.fft.fftshift(torch.fft.fft2(exit_wave)))\n",
    "    F1 = torch.nn.functional.interpolate(F1.unsqueeze(0).unsqueeze(0),size=(probesize),mode='bilinear').squeeze()\n",
    "    F1 = (F1)[EWCI[0]:-EWCI[1],EWCI[2]:-EWCI[3]]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=[15,10])\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.imshow(torch.abs(pre_EW).cpu(),aspect=0.1)\n",
    "    plt.title('|Input slice|')\n",
    "    plt.xlabel(\"y (voxels)\")\n",
    "    plt.ylabel(\"x (voxels)\")\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.imshow(torch.abs(midEW).cpu(),aspect=0.1)\n",
    "    plt.title('|Slice after reflection|')\n",
    "    plt.xlabel(\"y (voxels)\")\n",
    "    plt.ylabel(\"x (voxels)\")\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.imshow(torch.abs(exit_wave).cpu(),aspect=0.1)\n",
    "    plt.title('|Exit wave| (final slice)')\n",
    "    plt.xlabel(\"y (voxels)\")\n",
    "    plt.ylabel(\"x (voxels)\")\n",
    "\n",
    "    # plt.figure(figsize=[5,5])\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.imshow(torch.log(torch.abs((F1))+1e-20).cpu(),aspect=1,vmin=recon_FFT_vmin,vmax=recon_FFT_vmax)\n",
    "    plt.title(\"FT[exit wave]\")\n",
    "    plt.xlabel(\"uy (voxels)\")\n",
    "    plt.ylabel(\"uz (voxels)\")\n",
    "    \n",
    "    # plt.figure(figsize=[10,5])\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.imshow((torch.abs(sideslice.cpu())),aspect='auto')\n",
    "    plt.title(\"side-on view\")\n",
    "    plt.xlabel(\"z (voxels)\")\n",
    "    plt.ylabel(\"x (voxels)\")\n",
    "\n",
    "    \n",
    "    print(\"exit wave norm\",torch.norm(torch.abs(F1)))\n",
    "    print(\"exit wave max\",torch.max(torch.abs(F1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095a46d0-a270-46ea-b979-c3c4e40412bb",
   "metadata": {},
   "source": [
    "## Assert that the exit wave simulation window size matches the data/detector window size.\n",
    "### not needed for simulated data, but useful for real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_size = (F1).size()\n",
    "\n",
    "print(\"size of GT  crop\",crop_window_size)\n",
    "print(\"size of EW\",F1_size)\n",
    "# print(\"difference\",(F1_size[0] - crop_window_size[0]),(F1_size[1] - crop_window_size[1]))\n",
    "# print(\"old EWCI\", EWCI)\n",
    "# print(\"new EWCI should be\",EWCI[0]+(F1_size[0] - crop_window_size[0])/2,EWCI[2]+(F1_size[1] - crop_window_size[1])/2)\n",
    "assert (F1_size[0] == crop_window_size[0]) & (F1_size[1] == crop_window_size[1]) , \"EWCI isnt the same\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38071855",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.plot(((torch.abs(midslice.cpu()))[:,int(full_sim_size[2]/2)]))\n",
    "\n",
    "plt.title(\"beam profile at midpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1392d5-c7e6-4280-bc0b-6acf7087a852",
   "metadata": {},
   "source": [
    "## Define beam footprint mask. This will be to aid with a real space constraint in the volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a7ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_footprint_radius_y_voxels = (1.9e-6/(voxel_size[1]*downscaling_factor_y))\n",
    "beam_footprint_radius_z_voxels = (1.9e-6*oversample_factor/np.sin(np.deg2rad(inc_angle_list[0])))/(slab_thickness*downscaling_factor_z)\n",
    "beam_footprint_ratio = beam_footprint_radius_z_voxels/beam_footprint_radius_y_voxels\n",
    "beam_footprint_buffer = 1\n",
    "beam_footprint_blur = 5\n",
    "beamfootprints = (torch.ones(1,xr.size(1),xr.size(2)))\n",
    "print(beamfootprints.size())\n",
    "for n1 in range(len(new_yposindex)):\n",
    "    \n",
    "    beamfootprints[:,(new_yposindex[n1][0]):(new_yposindex[n1][1]),\n",
    "                      (new_zposindex[n1][0]):(new_zposindex[n1][1])] += pg.make_prop_mask(beamfootprints[0,int(new_yposindex[n1][0]):int(new_yposindex[n1][1]),int(new_zposindex[n1][0]):int(new_zposindex[n1][1])].rot90(1),(beam_footprint_radius_y_voxels+beam_footprint_buffer).cpu().numpy(),beam_footprint_blur,beam_footprint_ratio).rot90(-1)+1e-3\n",
    "\n",
    "\n",
    "    \n",
    "iii = 2\n",
    "thisxrtest = xr[0,int(new_yposindex[iii][0]+yzpad):int(new_yposindex[iii][1]+yzpad),\n",
    "                   int(new_zposindex[iii][0]+yzpad):int(new_zposindex[iii][1]+yzpad)]\n",
    "masktest1 = pg.make_prop_mask(thisxrtest.rot90(1),(beam_footprint_radius_y_voxels+beam_footprint_buffer).cpu().numpy(),beam_footprint_blur,beam_footprint_ratio).rot90(-1)+1e-4\n",
    "\n",
    "plt.figure(figsize=[10,5])\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(masktest1.detach().cpu(),aspect=2)\n",
    "plt.title(\"single scan footprint mask\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(torch.abs(midslice).detach().cpu(),aspect=2/oversample_factor)\n",
    "plt.title(\"beam footprint on substrate\")\n",
    "plt.figure(figsize=[15,5])\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(beamfootprints[0,:,:].cpu(),aspect=0.9), plt.colorbar()\n",
    "plt.title(\"beam footprints with mask applied\")\n",
    "\n",
    "beam_footprints_binary = beamfootprints.clone()\n",
    "beam_footprints_binary[beam_footprints_binary<2] = 0\n",
    "beam_footprints_binary[beam_footprints_binary>=2] = 1\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(beam_footprints_binary[0,:,:].cpu(),aspect=0.9), plt.colorbar()\n",
    "plt.title(\"beam footprints binary mask\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b23c64-9614-4d74-9f3c-89e1c460d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create ground truth structure.\n",
    "\n",
    "modulated_spokes_inds = {\n",
    "    1: (60, 150),\n",
    "    4: (70, 160),\n",
    "    7: (80, 170),\n",
    "    10: (90, 180),\n",
    "    13: (100, 190),\n",
    "    16: (110, 200),\n",
    "    19: (120, 200),\n",
    "    22: (130, 200),\n",
    "    24: (140, 200),\n",
    "    # 25: (100, 200),\n",
    "    # 28: (110, 200),\n",
    "    # 31: (120, 200),\n",
    "    # 34: (130, 200),\n",
    "\n",
    "    \n",
    "    \n",
    "}\n",
    "ground_truth_image = pg.generate_per_spoke_modulated_siemens_star(width=xr_z_size,\n",
    "                                                               height=xr_y_size,\n",
    "                                                               num_spokes=25,\n",
    "                                                               r_inner=15, \n",
    "                                                               r_outer=200,\n",
    "                                                               modulated_spokes=modulated_spokes_inds)\n",
    "# ground_truth_image = generate_custom_modulated_siemens_star(\n",
    "#     width=xr_z_size, height=xr_y_size,num_spokes=35,r_inner=15, r_outer=200,r_inner_alt=80, r_outer_alt=150,modulated_spoke_indices=[1,4,8,13,19,26,34])\n",
    "ny, nx = ground_truth_image.squeeze().shape\n",
    "extent = [0, nx * slab_thickness.cpu()*1e6, 0, ny * voxel_size[1].cpu()*1e6]\n",
    "plt.imshow(ground_truth_image.squeeze().cpu(),extent=extent,aspect='auto'),plt.colorbar()\n",
    "plt.title(\"Ground Truth\")\n",
    "plt.ylabel(\"y (μm)\")\n",
    "plt.xlabel(\"z (μm)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3140e9c-c243-42e6-b41a-022ab345d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create simulated diffrac patterns:\n",
    "with torch.no_grad():\n",
    "    GTs = torch.zeros_like(GT)\n",
    "    this_GT_str = ground_truth_image\n",
    "    for iii in range(num_scans):\n",
    "            \n",
    "            print(\"creating sim data diffrac. patterns:\",(iii+1), \"/\", num_scans,end=\"\\r\")\n",
    "            this_xr = pg.fill_3d_tensor(this_GT_str[0,int(new_yposindex[iii][0]+yzpad):int(new_yposindex[iii][1]+yzpad),\n",
    "                           int(new_zposindex[iii][0]+yzpad):int(new_zposindex[iii][1]+yzpad)],params_size[0],params_size,oversample_structure,oversample_factor)\n",
    "            sim_probe_in = pg.combine_probe_modes(probes_param,0,scan_identifier_list)\n",
    "            waveout,_ = pg.multislice_3stage(\n",
    "                    this_xr,\n",
    "                    full_sim_size, params_size, voxel_size, slab_thickness,lambda_val,\n",
    "                    inc_angle_list[iii], slab_pad_pre, slab_pad_post,post_prop_dist_multiplier, sim_probe_in,\n",
    "                    probe_buffer,probe_substrate_buffer,1,shift_amount,substrate_layers,\n",
    "                    init_xr_substrateamt,top_buffer,0,subpixel_shifts_y[iii],subpixel_shifts_z[iii],\n",
    "                hx_shift[int(scan_identifier_list[iii])],hz_shift[int(scan_identifier_list[iii])],Audelta,Aubeta)\n",
    "                #crop exit wave\n",
    "            out1 = torch.abs(waveout[EWCI[0]:-EWCI[1],EWCI[2]:-EWCI[3]])#*mean_1d_perscan[:,:,iii]\n",
    "            \n",
    "            GTs[:,:,iii] = out1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c43e09-5f38-4310-a2a4-8f9a2dd40693",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # plt.imshow(this_xr[-2,:,:].cpu())\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(torch.log(GTs[:,:,4]).cpu()),plt.colorbar()\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.imshow(this_GT_str[0,int(new_yposindex[iii][0]+yzpad):int(new_yposindex[iii][1]+yzpad),\n",
    "                           int(new_zposindex[iii][0]+yzpad):int(new_zposindex[iii][1]+yzpad)].cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148b413e-a35c-4fb3-9e21-46622a21dece",
   "metadata": {},
   "source": [
    "# Main Loop\n",
    "\n",
    "### by default this prints out an image of the probe and reconstruction after each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45065a40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flux_ratio = 1\n",
    "fig = plt.figure(figsize=[10,10])\n",
    "\n",
    "\n",
    "for i in range(num_iters):\n",
    "\n",
    "    mstime1 = time.time()\n",
    "    scan_orders = (list(range(num_scans)))\n",
    "    random.shuffle(scan_orders)\n",
    "    scan_counter = 0\n",
    "    #zero grad \"storage\" tensors\n",
    "    probes_cumulative_grad = torch.zeros_like(probes_param)\n",
    "    spsz_cumulative = torch.zeros_like(subpixel_shifts_z)\n",
    "    spsy_cumulative = torch.zeros_like(subpixel_shifts_y)\n",
    "    hx_cumulative = torch.zeros_like(hx_shift)\n",
    "    hz_cumulative = torch.zeros_like(hz_shift)\n",
    "\n",
    "    xrg *= 0\n",
    "\n",
    "    for iii in scan_orders:\n",
    "        #zero optimizers\n",
    "        pg.zero_grads(optimizer,optimizer_adam,probe_optimizer,prop_optim,optimize_scan_offsets,scan_positions_optim,use_noise,noise_optim)\n",
    "        #choose the corresponding probe for this scan.\n",
    "        this_probe_in = pg.combine_probe_modes(probes_param,iii,scan_identifier_list)\n",
    "         #choose the corresponding position of xr for this scan.\n",
    "        this_xr = pg.fill_3d_tensor((xr)[0,int(new_yposindex[iii][0]+yzpad):int(new_yposindex[iii][1]+yzpad),\n",
    "               int(new_zposindex[iii][0]+yzpad):int(new_zposindex[iii][1]+yzpad)],params_size[0],params_size,oversample_structure,oversample_factor)\n",
    "        \n",
    "\n",
    "        #begin forward pass of multislice:\n",
    "        waveout,_ = pg.multislice_3stage(\n",
    "            this_xr,\n",
    "            full_sim_size, params_size, voxel_size, slab_thickness,lambda_val,\n",
    "            inc_angle_list[iii], slab_pad_pre, slab_pad_post,post_prop_dist_multiplier, this_probe_in,\n",
    "            probe_buffer,probe_substrate_buffer,wave_deletion_mask,shift_amount,substrate_layers,\n",
    "            init_xr_substrateamt,top_buffer,0,subpixel_shifts_y[iii],\n",
    "            subpixel_shifts_z[iii],hx_shift[int(scan_identifier_list[iii])],\n",
    "            hz_shift[int(scan_identifier_list[iii])],Audelta,Aubeta)\n",
    "        #crop exit wave\n",
    "        out1 = torch.abs(waveout[EWCI[0]:-EWCI[1],EWCI[2]:-EWCI[3]])\n",
    "        with torch.no_grad(): \n",
    "            out1.data[torch.isnan(out1.data)] = 0\n",
    "        #apply Total Variation Penalties / other regularizers\n",
    "        tvx,tvy,tvz,tv_total = pg.apply_tv(xr,tvx_alpha,tvy_alpha,tvz_alpha,tvt_alpha,i,iii,tv_start)\n",
    "        #select corresponding diffraction pattern/data      \n",
    "        this_GT = GTs[:,:,iii]#*detector_mask_crop\n",
    "\n",
    "        #calculate the loss \n",
    "        if use_noise == 1:\n",
    "            this_diff = (torch.abs((torch.abs(this_GT)) - (((out1)))))**2+noise_guess[:,:,iii]\n",
    "            loss = torch.nanmean(this_diff)+tv_total\n",
    "        else:\n",
    "            loss = torch.nanmean((torch.abs((torch.abs(this_GT)) - (((out1)))))**2)+tv_total\n",
    "\n",
    "        allocated_memory = torch.cuda.memory_allocated()\n",
    "        backtime1 = time.time()\n",
    "        \n",
    "        ### calculate backward ###\n",
    "        loss.backward()\n",
    "        #after backward:\n",
    "        #store + optimize scan offsets \n",
    "        pg.store_scan_offset_gradients(subpixel_shifts_z,subpixel_shifts_y,hx_shift,hz_shift,optimize_scan_offsets,i)\n",
    "        #start storing gradients of the recon structure into xrg\n",
    "        pg.store_xr_gradients(xr, xrg,iii, new_yposindex, new_zposindex, yzpad, i,do_gradient_accumulation)\n",
    "        #accumulate grads for probe param and prop amt.\n",
    "        with torch.no_grad():\n",
    "            probes_cumulative_grad += probes_param.grad\n",
    "            probes_cumulative_grad[torch.isnan(probes_cumulative_grad)] = 0\n",
    "        pg.store_noise_gradients(noise_optim,noise_guess,use_noise,noise_mean,noise_std)\n",
    "        backtime2 = time.time()\n",
    "        scan_counter += 1\n",
    "        loss_tracker[i,iii] = loss.item()\n",
    "        pg.print_progress_bar(scan_counter + 1, num_scans)\n",
    "        \n",
    "        ### end loop over scans###\n",
    "    \n",
    "    #reapply gradients and actually update the structure\n",
    "    pg.apply_gradients_and_update(optimizer,optimizer_adam,xr,xrg,beamfootprints,params_size,beam_footprints_binary,\n",
    "                                  do_gradient_accumulation,using_n_scans_per_pixel,i,\n",
    "                                  spsy_cumulative,spsz_cumulative,hx_cumulative,hz_cumulative,\n",
    "                                  subpixel_shifts_y,subpixel_shifts_z,hx_shift,hz_shift,\n",
    "                                  probes_param,probes_cumulative_grad,num_scans)\n",
    "    pg.apply_probe_constraints(probestart,probe_optimizer,probe_grads_target,probes_cumulative_grad,num_scans,i,probes_param,psr)\n",
    "    pg.apply_LR_scheduler(i,divergence_count_start,loss_tracker,divergence_thr,grads_target,probe_grads_target,optimizer,optimizer_adam,probe_optimizer,tvt_alpha) #this reduces LRs if loss function is increasing.             \n",
    "    \n",
    "\n",
    "    xr.data = torch.clamp(xr.data,0,params_size[0])\n",
    "    mstime2 = time.time()\n",
    "       \n",
    "    \n",
    "    #print metrics for losses and parameters\n",
    "    pg.print_metrics(hz_shift,hx_shift,i,iii,num_iters,loss_tracker,allocated_memory,mstime2,mstime1,backtime2,backtime1,GT,out1,tvx,tvy,tvz,tv_total,optimizer,probe_optimizer)\n",
    "\n",
    "    #print output at each iteration. Comment out to turn off.\n",
    "    fig = pg.plot_reconstruction(fig, xr, iii, probes_param, out1, this_GT,\n",
    "                        dzz, dzy, yzpad, use_multiple_probe_modes,\n",
    "                        probe_vmax, recon_FFT_vmin, recon_FFT_vmax,\n",
    "                        psr, i, flux_ratio,scan_identifier_list)\n",
    "    \n",
    "    \n",
    "total_sim_end_time = time.time()\n",
    "print()\n",
    "print(\"finished\")\n",
    "\n",
    "print(\"total time for\",num_iters,\"iters:\", \"%2.2f\" % ((total_sim_end_time-total_sim_start_time)/60),\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7a09ac-ee8b-4249-8826-072f42ecbadf",
   "metadata": {},
   "source": [
    "# View Reconstruction Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee54c14-53d7-4450-8503-c6c09badf2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_3d_tensor(A,structure_height,params_size):\n",
    "    width,height = A.shape\n",
    "    output3d = A.repeat(structure_height,1,1)-torch.arange(structure_height).unsqueeze(1).unsqueeze(1).expand(structure_height,width,height)\n",
    "    output3d = torch.clamp(output3d,0,1)\n",
    "    return output3d.flip(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2becde-7aeb-4995-b313-ff2bdb64e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    plt.figure(figsize=[15,10])\n",
    "    plt.subplot(2,2,1)\n",
    "    \n",
    "    \n",
    "    ny, nx = xr.squeeze().shape\n",
    "    extent = [0, nx * slab_thickness.cpu()*1e6, 0, ny * voxel_size[1].cpu()*1e6]\n",
    "    plt.imshow((xr*voxel_size[0]*1e9).squeeze().cpu(),extent=extent,aspect='auto')\n",
    "    cbar1 = plt.colorbar()\n",
    "    cbar1.set_label(\"height (nm)\")\n",
    "    plt.title(\"reconstruction\")\n",
    "    plt.ylabel(\"y (μm)\")\n",
    "    plt.xlabel(\"z (μm)\")\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.imshow((ground_truth_image*voxel_size[0]*1e9).squeeze().cpu(),extent=extent,aspect='auto')\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.ylabel(\"y (μm)\")\n",
    "    plt.xlabel(\"z (μm)\")\n",
    "    cbar2 = plt.colorbar()\n",
    "    cbar2.set_label(\"height (nm)\")\n",
    "\n",
    "    plt.subplot(2,2,3)\n",
    "    recon_3d = display_3d_tensor(xr.squeeze(),params_size[0],params_size)\n",
    "    nz,ny, nx = recon_3d.shape\n",
    "    extent2 = [0, nx * slab_thickness.cpu()*1e6, 0, nz * voxel_size[0].cpu()*1e9]\n",
    "    plt.imshow((recon_3d)[:,250,:].cpu(),extent=extent2,aspect='auto',interpolation='none')\n",
    "    plt.title(\"Reconstruction (side view)\")\n",
    "    plt.ylabel(\"x (nm)\")\n",
    "    plt.xlabel(\"z (μm)\")\n",
    "    cbar2 = plt.colorbar()\n",
    "    cbar2.set_label(\"intensity (frac Au)\")\n",
    "\n",
    "    plt.subplot(2,2,4)\n",
    "    GT_3d = display_3d_tensor(ground_truth_image.squeeze(),params_size[0],params_size)\n",
    "    plt.imshow(GT_3d[:,250,:].cpu(),extent=extent2,aspect='auto',interpolation='none')\n",
    "    plt.title(\"Ground Truth (side view)\")\n",
    "    plt.ylabel(\"x (nm)\")\n",
    "    plt.xlabel(\"z (μm)\")\n",
    "    cbar2 = plt.colorbar()\n",
    "    cbar2.set_label(\"intensity (frac Au)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f9329-df59-49c4-beee-31dbae185cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=[10,5])\n",
    "\n",
    "lossmeans = np.mean(loss_tracker+1e-20,1)\n",
    "losserrs = np.std(loss_tracker+1e-20,1)\n",
    "plt.errorbar(np.arange(0,num_iters),lossmeans,losserrs)\n",
    "plt.plot((loss_tracker),alpha=0.1)\n",
    "plt.xlim([0,(i+5)])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"n iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dfa36a-1486-424a-870e-8f4835886cf5",
   "metadata": {},
   "source": [
    "# Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc408cfb-49f5-4eb2-b877-641e0b0ecc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_filepath = '/outputs/' \n",
    "save_filename = 'demo_script_output'\n",
    "today_date = datetime.today().strftime('%d-%m-%Y')\n",
    "full_filename = f\"{save_filepath}{save_filename}_{today_date}.pt\"\n",
    "print(\"full filename\",full_filename)\n",
    "\n",
    "metadata = {\n",
    "    \"slab_thickness\": slab_thickness,\n",
    "    \"simulation_size\": full_sim_size,\n",
    "    \"voxel_size\": voxel_size,\n",
    "    \"probes\": probes_param,\n",
    "    \"oversample_factor\": oversample_factor,\n",
    "    \"num_inc_angles\": len(np.unique(inc_angle_list)),\n",
    "    \"inc_angles\": np.unique(inc_angle_list),\n",
    "    \"num_scans\": num_scans,    \n",
    "    \"loss_function\": loss_tracker,\n",
    "\n",
    "    \"GT\": ground_truth_image,\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "# Save tensor and metadata\n",
    "torch.save({\"recon\": xr.detach(), \"metadata\": metadata}, full_filename)\n",
    "\n",
    "print(f\"\\n Reconstruction and metadata saved successfully to:\\n→ {os.path.abspath(full_filename)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028d42d8-1c7c-4fbe-b7a5-cb7e9ad8ea1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
